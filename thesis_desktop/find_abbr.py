import re


background = ("\chapter{Background} Medicine has taken quantum leaps toward maintaining homeostasis within the past century, targeting diseases in a range of specific ways. However, creating universal and effective treatment of cancer and many autoimmune conditions has proven a significant challenge. Simultaneously, infectious diseases are at risk of becoming yet more challenging to treat due to the demising effect of antibiotics. Hence, the need for novel solutions is as essential as ever. Today, a one-size-fits-all approach is prevalent, without much consideration of the genetic material of the subjects. Herein lies unexplored therapeutic potential both regarding choosing the most appropriate regimen and regarding developing new types of personalized drugs. To bridge this gap between potential and solution, an understanding of the immunological responses and genetic differences are required. Hence, there has been an emergence of research into the mechanisms and behavior of the adaptive immune system in response to different therapy regimes, both experimentally and in silico \cite{Maciejko2017CancerApproaches}, \cite{Holt2017InterpretingRepertoire}. This thesis investigates the interface between immune response and genetic differences by suggesting a way to measure a distance between two T-cell receptors based on their mainchain structure and residue sequence. Such a distance metric can enable the classification of T-cell receptors, which is desirable, as it allows an understanding of which elements control binding and can inform practitioners of the best choice of therapy. Hence, a step on the way to personalized medicine. The following pages contain an introduction to the context of this thesis, beginning with a review of the main elements of disease and an examination of t-cell properties and receptors. \section{Diseases lacking universally effective Therapy Regimens} Diseases lacking universal treatment are the focus of this thesis. They are described below in broad terms to understand why this lack is prevalent and why therapeutic solutions based on genetic markup might hold answers. The following text is a description of the basic cellular characteristic and healthy immune response, followed by current treatment options for each of the disease classes. \subsection{Cancer} Cancer is a broad term for the formation and proliferation of malignant cells in a host. Cancer arises from failures in the mechanisms that usually control cell growth and proliferation. Therefore, it follows that cancer occurs when these mechanisms malfunction and allow the cells to proliferate uncontrollably. Malfunctions are a result of genetic damage, and the inappropriate cell growth is either due to; Lack of regulation, increased gene expression, or expression of an error. Usually, DNA damage is repaired efficiently and conservatively by cell growth checkpoints and specialized repair systems. These retain the cell growth and repair the different types of lesions. One mutation does not result in cancer, but a cell with the ability to grow uncontrollably without detection gives favorable conditions for additional mutations \cite{Bozic2010AccumulationProgression}, \cite{LodishMolecularBiology}. If mutations lead to cancer, the immune system usually fights it using its surveillance system. Here the innate and adaptive immunity recognize and destroy developing tumors before they are clinically apparent. The adaptive T-cells eliminate cancer cells based on expressed protein fragments, while the innate NK cells eliminate cancer cells based on surface-expressed abnormalities. If this system fails, the cancer cells grow and induce an immune-suppressive microenvironment and become clinically apparent tumors in need of treatment \cite{Dunn2004TheImmunoediting}.The traditional cancer treatment includes surgery, radiation, and chemotherapy. Surgery and radiation are local treatments, while chemotherapy is a systemic class of drugs. They differ as the local treatments remove or attack the primary tumor site, while the systemic chemotherapy induces apoptosis in fast-dividing cells, thereby reducing the primary tumor and attacking metastasis. The faults of chemotherapy are, however, that dosage can be unpredictable, drug resistance is prevalent, and the side effects are many and severe. Once the patient develops resistance to one type of chemo, other resistances follows swiftly after \cite{Guo2017TumorImmunity}. Consequently, the problem with traditional treatment is ineffectiveness and harsh side-effects. Presently immunotherapy has become a relatively routine practice.  Methods vary from checkpoint inhibitors to adoptive t-cell transfer and monoclonal antibodies. Immunotherapies show promising results, although not all patients respond in a unified way. Survival rates are still not understood in detail, and there is a largely empirical approach to designing immunotherapies \cite{Marconcini2015CurrentMelanoma}. Despite its success, one of the main questions still associated with immunotherapy is: why do some patients respond so well, while others do not? A hypothesis is that responders have some genetic similarities within their T-cell receptors, why their T-cells react to the treatment. \subsection{Autoimmune Diseases} Autoimmune disease is a broad term for diseases caused by a reaction to self-antigens; they affect approximately 3-5\% of the studied populations and have considerable modality and mortality rates \cite{Eaton2007EpidemiologyDenmark}. Autoimmune reactions arise when the mechanisms for self-detection fails. Thus, letting self-reactive lymphocytes leave the thymus. The self-detection is a system consisting of multiple layers. Including negative selection, where self-antigens are tested for binding by the new cell in the thymus. The subsequent layers of protection incorporate \textit{Antigen Segregation}, a physical barrier to self-antigen access to the lymphoid system. Peripheral anergy, inactivation due to weak co-stimulation. Regulatory t-cells are suppressing the autoimmunity through the release of suppressive cytokines. Moreover, finally induced cell death by apoptosis. Hence, developing an autoimmune disease requires evasion of multiple checkpoints \cite{MurphyNINTHImmunology}.  Autoimmune reactions become a disease when self-binding T or B-cells react to own tissue initiating inflammation by generating a positive feedback loop, where the tissue presented by APC to the t-cell lets the t-cell clone proliferate and generate immune responses to more self tissue. At the same time, the B-cells secrete antibodies that too bind more of the own tissue. Consequently, using all the immunological tools developed to fight an intruder to fight self. Some of the autoimmune diseases are local organ-specific, while others are systemic \cite{Wang2015HumanUpdate}. In order to develop an autoimmune disease, the individual is either infected by an immunomodulating agent or is pre-disposed due to genetic factors, respectively, as HIV and Diabetes type 1 \cite{MurphyNINTHImmunology}. The infections are some of the more studied causes of autoimmune disease, yet even with correlation, causation seems hard to decipher. One example of this is the Ebstein-Barr virus (EBV) found as a cofactor in several autoimmune diseases, including systemic lupus erythematosus, Sjogren's syndrome, rheumatoid arthritis \cite{Draborg2013Epstein-barrDiseases}, \cite{Abdelrahman2014Epstein-BarrSclerosis}, and primary biliary cirrhosis \cite{Morshed1992IncreasedPatients.}. However, there has also been established a correlation between EBV and distinct cancer types \cite{ElguideOliveira2016ViralCancers}. Treating autoimmune disease has traditionally been a difficult task. For particular autoimmune diseases, the function of the damaged tissue can sometimes be replaced, such as with insulin. Nevertheless, the typical treatment of autoimmune disease is immunosuppressive drugs \cite{RangJournals}  — new drugs to treat autoimmunity attempt to re-establish tolerance using biological agents to block immunological pathways. Hence, autoimmunity can be treated today but not cured \cite{Wang2015HumanUpdate}. \subsection{Infectious Diseases} Infectious disease is a term describing diseases arising from infection with a foreign agent, causing an immune reaction in the form of inflammation. The broad groups of foreign agents include viral, fungi, protozoans, gram-negative, and gram-positive bacteria \cite{MurphyNINTHImmunology}. Each of these groups invades the host, and the healthy immune response includes uptake by APC and presentation on an MHC molecule to the t-cell. There are two classes of MHC molecules. When a CD8 positive t-cell bind a peptide on the MHC class I molecule, an IL-2 signal will get the T-cells to proliferate and leave the lymph node to fight intracellular pathogens. When a CD4 positive t-cell bind a peptide on the MHC class II molecule, differentiation of the t-cell is initiated, depending on the cytokine released. An IL-12 and IFN-\(\gamma\) signal result in a Th1 cell, that fights intracellular bacteria and virus. An IL-4 signal results in the cell becoming a Th2 cell that fights parasites. A TGF-\(\beta\) and IL-6 signal will result in a Th17 cell that fights extracellular bacteria and fungi. There are two further classes, the TGF-\(\beta\) mediated Treg that downregulate the other T-cells and the Tfh cells induced by IL-6 that assist b-cells. If the healthy immune response fails, specific treatment exists to prevent or treat many of these species, such as prophylactic vaccinations against infection with a specific virus. Some groups have common characteristics that allow the use of broader treatment regimens, such as antibiotics, towards bacteria. However, in recent years the world has seen a demise of antibiotics  \cite{Laxminarayan2013AntibioticSolutions}, which can lead to modality and even mortality after infection. Therefore studying the healthy immunological response to these bacteria is paramount.  \section{The role of T-cells in the Immunological Response} The T-cells are the killers of the immune system, and recruiting the t-cells to fight disease would be a potent tool in new medicine. Hence, the hypothesis is that to develop targeted therapy regimes, understanding of the repertories and differences between individuals is an integral part of understanding the mechanisms of T-cell reactivity and action in individuals. An understanding of the repertories can be obtained based on relative abundance and similarity of t-cell receptors \cite{TOM2012MeasuringSimilarity}. These pave the road for understanding differences between repertoires, using hierarchical clustering, diversity estimates and comparisons of specific sequences between repertoires \cite{Holt2017InterpretingRepertoire}, \cite{Glanville2017IdentifyingRepertoire}, \cite{Dash2017QuantifiableRepertoires}, \cite{Rudqvist2018RadiotherapyCells}.\section{Aim of thesis} To summarise the high dimensional data of the T-cell repertoires, a suitable TCR similarity metric must be defined. The current state of the art in measuring the similarity of TCRs relies on comparisons of primary sequence information, using, e.g., sequence overlap, or conservation of short stretches of amino acids (AA). These methods include pairwise sequence comparisons such as alignment scoring metrics \cite{Thakkar2019BalancingSimilarity}, ImmunoMap-Distance \cite{Sidhom2018ImmunoMap:Access}, TCRdist \cite{Dash2017QuantifiableRepertoires} or comparisons of similarity between whole repertoires such as frequencies of k-mer stretches of AA sequences in whole repertoire \cite{Thomas2014TrackingSequence}, \cite{Glanville2017IdentifyingRepertoire}. There exist several relevant distance measures \cite{Priel2018NetworkFormation}. However, there seems to be no clear advantage of choosing between them from a biological point of view. As the highly differentiated conformational structure and lengths of CDR3s between T-cells and as the conformation of the CDR3 region greatly influence binding to MHC:peptide complex \cite{Jones2008DistinctOrientation}, it follows that a similarity metric based exclusively on primary sequence information might be inadequate at capturing biological similarity. This thesis aims to produce a distance metric to calculate the similarity between CDRs of the TCRβ from primary sequences, based on 3D structural predictions performed with structure prediction tools such as LYRA \cite{Klausen2015LYRAModeling} that have been tested and trained on solved TCR and antibody structures. In order to ensure the metric captures the biological meaning, for instance, accounting for the fact that similar TCRs bind to the same antigen, the incorporation of other descriptors will give biological substance to the metric.")
aim_hypo = ("\chapter{Introduction to Structure and Scientific Approach} This small chapter contains the following: A hypothesis on which this research is built, the aim of this master thesis, and the limitations to the project. Furthermore, a short scientific theoretical standpoint, and lastly, is a brief walkthrough of the content of the thesis. \section{Hypothesis}The hypothesis state that understanding T-cell receptors and differences between individuals are an integral part of understanding the mechanisms of T-cell reactivity and action. An understanding of the repertories can be obtained based on relative abundance and similarity of t-cell receptors \cite{TOM2012MeasuringSimilarity}. To summarise the high dimensional data of the T-cell repertoires, a suitable TCR similarity metric must be defined. The current state of the art in measuring the similarity of TCRs relies on comparisons of primary sequence information, using, e.g., sequence overlap, or conservation of short stretches of amino acids (AA). These methods include pairwise sequence comparisons such as alignment scoring metrics \cite{Thakkar2019BalancingSimilarity}, ImmunoMap-Distance \cite{Sidhom2018ImmunoMap:Access}, TCRdist \cite{Dash2017QuantifiableRepertoires} or comparisons of similarity between whole repertoires such as frequencies of k-mer stretches of AA sequences in whole repertoire \cite{Thomas2014TrackingSequence}, \cite{Glanville2017IdentifyingRepertoire}. There exist several relevant distance measures \cite{Priel2018NetworkFormation}. However, there seems to be no clear advantage of choosing between them from a biological point of view. As the highly differentiated conformational structure and lengths of CDR3s between T-cells and as the conformation of the CDR3 region greatly influence binding to MHC:peptide complex \cite{Jones2008DistinctOrientation}, it follows that a similarity metric based exclusively on primary sequence information might be inadequate at capturing biological similarity. A biological meaningful distance metric can differentiate between T-cell receptors based on the epitope to which they bind. \section{Aim of thesis}This thesis aims to produce a distance metric to calculate the similarity between CDRs of the TCRβ from primary sequences, based on 3D structural predictions performed with structure prediction tools such as LYRA \cite{Klausen2015LYRAModeling} that have been tested and trained on solved TCR and antibody structures. To ensure the metric captures the biological meaning, for instance, accounting for the fact that similar TCRs bind to the same antigen, the incorporation of other descriptors will give biological substance to the metric. \section{Assumptions and Limitations}Only the beta subunit of the T-cell receptor is analyzed in this thesis. This limitation is set in place due to 1) time constraints and 2) lack of paired sequences. This choice is justified based on the fact that the beta subunit is primarily in contact with the epitope, and the assumption that it, therefore, is more important in mediating binding.\section{Scientific methodlogy}This master's thesis is written using the scientific method. Hence, striving for testing parameters isolated without introducing errors and only drawing conclusions based on the emerging empirical evidence. \section{Structure and Content}The structure of this thesis is the classical structure introduction, theory, methods, results, discussion, and conclusion. Yet, the theory has been spread over three chapters, which are designed to explain the basis on which the distance metric was developed. The first of these chapters deals with the immunological aspect of the metric ensuring that the distance will be measured on the vital elements of the t-cell receptor. Next, is a chapter dealing with proteins, explaining how the t-cell receptor can be modeled and compared. The methods used to develop the metric itself is presented here. Finally the last theoretical chapter present how these protein comparison tools of the relevant immunological elements can be converted into a mathematical framework of a distance metric. The method chapter is restricted to an explanation of how these theories were put into action. The results are spread over four chapters. The first two deal with developing the metic by testing each method in a vacuum, while the third chapter will combine methods, deduce the metic based on the emerged empirical evidence. Lastly, the metric is compared to state of the art to assess the true quality of the metric. Finally is the discussion and conclusion of the master's thesis. ")
Theory1 =("\chapter{Immunological Impact: The T-cell receptor and Repertoire} This first of three theoretical chapters is a presentation of the T-cell receptor. On the following pages is a description of the T-cell receptors function and genetic markup. Furthermore, a summary of the term \textit{TCR repertoire} and a description of diversity and similarity in this context.  \section{T-cell receptor} \begin{figure}[h] \includegraphics[width=\textwidth]{graphics/Theory/TCR_MHC_for_theory} \caption[TCR:p:MHC]{A schematic representation of the interaction between TCRs in red, the epitope in black, and the MHC molecule in grey. The top panel is a simple cartoon representation of the interaction and illustration of the difference in the two MHC classes. The lower panel is a pymol generated image of the solved complexes: 1BD2 \cite{Ding1998TwoAcids} and 1FYT \cite{Hennecke2000StructureHLA-DR1.}. It is possible to see the difference in length of the epitope, as the MHC II presents a longer amino acid sequence than MHC class I.} \label{fig:TCRMHC_pymol} \centering \end{figure} The TCR is a membrane-bound receptor that consists of two chains: an \(\alpha \) and \(\beta\) chain or a \(\gamma\) and \(\delta\) chain. The \(\gamma\)/\(\delta\) subtype represents a small subset of the T-cells in peripheral blood, why only \(\alpha \)/\(\beta\) T-cells are analyzed here. The two chains or subunits collectively interact with a peptide presented on the MHC molecule in combination with the CD8 or CD4 co-receptor, as shown in figure \ref{fig:TCRMHC_pymol}. The modulation of the interaction is by the complementary-determining regions (CDRs) of the TCR facing the MHC molecule. Each subunit has three CDRs named accordingly; CDR1, CDR2, and CDR3 \cite{MurphyNINTHImmunology}. Though all the CDRs are part of the paratope, they have different parts to play. While CDR1 and CDR2 mainly bind the MHC itself, CDR3 binds the epitope, accounting for most of the pathogenic recognition. The epitopes bound in the MHC peptide TCR (MHC:p:TCR) complex is exclusively protein fragments, with a length of respectively 8-9 amino acids when bound to MHC class I and 24-25 amino acids when bound to MHC class II. In both cases, the fragments are bound in their primary structure. These fragments are not specific, as the MHC molecules have promiscuous binding specificity, they only need to be different from the host \cite{MurphyNINTHImmunology}. %\subsection{Activation and functionality of the T-cell receptor} Once an epitope is bound to the TCR, it initiates a cascade of phosphorylations that results in the activation of transcription factors NFKB, NFAT, and AP-1. These transcription factors induce specific gene transcription leading to cell proliferation and differentiation into effector cells. The differentiation depends on the cytokines present. The innate immune system primarily releases cytokines. The specific cytokine released depends on the nature of the presented fragment \cite{MurphyNINTHImmunology}.  \subsection{T-cell receptor V(D)J Loci and gene re-arrangement} Genetic information for the production, the loci, of the TCR is stored respectively at the 7th and 14th chromosome. The TCR chains are created separately and paired together as a heterodimer after translation. Both chains have several gene segments encoding the different parts of the receptor. The following text is a description of the achievement of diversity by the creation of the  \(\beta\)-chain.\subsubsection{Assembly of the receptor \(\beta\) Subunit} \caption[Gene usage in the TCR \(\beta\)-chain]{A cartoon representation of the gene usage in the \(\beta\)-chain including the V, D and J gene segments and the nucleotide ligation segments P, N, P. The nucleotide sequence is chosen at random to illustrate the palindromic and non-templated nucleotides} Assembly of one V-gene, one J-gene, one D-gene, and one C-gene form one \(\beta\) chain. Conduction of this assembly follows several steps; first is the variable part of the chain is created by transcribing genes and joining these together with an enzymatic system. This enzymatic system consists of the lymphoid-specific recombinase protein (RAG) that create double-strand breaks at the recombination signal sequences (RSS) flanking the V, D and J genes and create a DNA hairpin at the break site.  The next step in the enzymatic system is the non-homologous end-joining. Facilitation of the non-homologous end-joining is by the Artemis:DNA-PK complex that opens the DNA hairpin and generates short palindromic nucleotide sequences (P-nucleotides), by making the remainder of the RSS single-stranded. Terminal deoxynucleotidyl transferase enzyme (TdT) directs the third step. TdT adds Non-templated nucleotides (N-nucleotides), which are paired and thus bind the two gene segments together.  Here, removal of the non-binding nucleotides and filling of the gaps by DNA synthesis and ligation to form a coding joint. This joint now contains a P-, N- and P-nucleotide segment between variable and joining or between the joining and diversity segment \cite{Krangel2009MechanicsRearrangement}. The assembly is illustrated in figure \ref{fig:mesh1}. begin{figure}[h] \includegraphics[width=\textwidth]{graphics/Theory/BETACHAIN_cartoon_CDR} \caption[Gene usage in the TCR \(\beta\)-chain CDR loops]{A cartoon representation of the gene usage in the CDR loops. The presentation is strongly distorted, and its purpose is to illustrate how the V-gene encodes CDR1, CDR2, and how the V, D and J gene encodes CDR3}     \label{fig:mesh2} centering \end{figure} \subsubsection{Diversity in the assembly of the T-cell receptor} As one of each segment is used to create the \(\beta\) chain, there are 2700 combinatorial options, accounting for the combinatorial diversity. The relatively random joints account for junctional diversity. This diversity is far harder to calculate but estimated to be around \(2*10^{11}\) options. Consequently, after joining a VDJ region, the resulting mRNA is translated and coupled with one of the constant regions \cite{MurphyNINTHImmunology}. Meanwhile, the \(\alpha \) chain also undergoes recombination. The \(\alpha \) chain locus is located at the 14th chromosome and contains approximately 70 V and 62 J segments. An estimate of the total diversity of TCRs is approximately \(10^{18}\) \cite{MurphyNINTHImmunology}. \caption[Structural representation of gene usage in the TCR \(\beta\)-chain CDR loops]{\textbf{The left panel} is a visual receptor representation created in pymol of the gene usage in the CDR regions. It is based on the crystal structure of PDBid: 1YMM \cite{Hahn2005UnconventionalReceptor}. Here the V-gene (TRBV20-1*01) is shown in red, the J gene (TRBJ2-1*01) is green and the supposed D gene is yellow while the nucleotides are blue. Gene usage found on IMGT \cite{Lefranc2014ImmunoglobulinImmunoinformatics.}. \textbf{The right panel} show a schematic illustration of the \(\beta\)-chain seen from above, with framework elements (non-CDR) labelled with letters corresponding to the IMGT nomenclature. The illustration is adapted from Al-Lazikani et al. 2000 \cite{Al-Lazikani2000CanonicalReceptors}} \subsubsection{Gene usage in Complementary determining regions} The hypervariable CDR sequences are encoded respectively by the v-gene for CDR1 and CDR2, while CDR3 is encoded by V, D, and J gene segments and modified by P- and N-nucleotides, why CDR3 has the most significant amount of variability. The high variability is biologically reasonable as the CDR1 and CDR2 bind primarily to the MHC molecule, whereas CDR3 binds directly with the epitope \cite{NationalCenterforBiotechnologyInformation2019NoTitle}. A simple illustration of the gene usage is illustrated in figure \ref{fig:mesh2}, while a three-dimensional rendering and a schematic representation is illustrated  in figure \ref{fig:mesh3} \section{The T-cell receptor Repertoire} A repertoire is \textit{a complete pool of expressed capabilities}. Here, it means the complete pool of binding specificity towards antigens. T-cells develop in the thymus, and a person's t-cell repertoire arise as a consequence of three things: \begin{itemize} \item Notch signaling. The notch is a receptor that transmits a signal to the naïve t-cell to switch on specific genes. First of all, to commit to the t-cell lineage and secondly to initiate t-cell receptor gene rearrangement.\item Positive selection. Positive selection is a survival signal to cells that are compatible with self MHC molecules. \item Negative selection in the thymus. The negative selection is a removal signal to cells that bind self-antigens on the MHC. \end{itemize} Under normal circumstances, a t-cell receptor from the repertoire binds the MHC molecule, and the epitope it is presenting. If the epitope is from self and the t-cell is self-tolerant, the t-cell does not induce apoptosis. Construction of the pool of TCRs employed by one individual happens mainly in childhood. TCR pool construction in childhood is evident both as the thymus shrinks with age, development rate lessen, and people who surgically have their thymus removed as adults rarely have problems with immunity. The main goal in the production of new lymphocytes is to generate a diverse repertoire of t-cell receptors widening the range of adaptive responses to pathogens. However, a person can only express a fraction of the total number of options in their lifetime \cite{MurphyNINTHImmunology}. TCR repertoires are analyzed in the lab by sequencing. Studying a repertoire is not a straight forward task, as the repertoire is dynamic and changes greatly with diseases. This change is partly due to the clonal expansion of one TCR as a response to a current infection, which might give the impression that only very few TCRs are active in a test sample. The overshadowing challenge here is to asses diversity \cite{Rosati2017OverviewAnalysis}.\subsection{Diversity}The mathematic estimation of the combinatorial and junctional diversity and the results on diversity measurements from the lab have hitherto not been compatible \cite{Rosati2017OverviewAnalysis}. The diversity measured in the lab is much smaller than the calculated diversity. This discrepancy is, in part, because it has been troublesome to get data until reason development of next-generation sequencing techniques. In part because different research groups have extracted and prepared samples differently, making the comparison of results difficult. It could also suggest that the diversity of the TCRs are not as seemingly large and random as first believed \cite{Rosati2017OverviewAnalysis}. Holt argued in 2017 \cite{Holt2017InterpretingRepertoire}, that the TCR repertoire could be read but not fully understood, and highlighted, that one of the reasons for this is the TCR promiscuity. One TCR can bind a variety of p:MHC and one p:MHC can bind a variety of TCRs. Expression of diversity is often an effective number calculated from two parameters: abundance and similarity. There is an assortment of ways to define these parameters. A generic notion is that abundance describes the proportions in which a unit is present, and similarity describes how similar two units are \cite{TOM2012MeasuringSimilarity}. Less generic notions are Shannon entropy and the Simpson index \cite{Glanville2017IdentifyingRepertoire}. In regards to t-cell receptors, to asses abundance and similarity, the following questions need to be answered: How do we asses abundance? The abundance of different t-cells is dynamic, as some specific clonal types are present when t-cells proliferate in response to non-self. Moreover, how similar do two TCRs need to be, for them to be of \textit{the same species}? Regarding abundance, we need to administer the sensitivity by controlling our sample size, and how much value we place on abundance \cite{TOM2012MeasuringSimilarity}. Administering sensitivity is primarily relevant when choosing data on which to develop the method.  Similarity, s, or dissimilarity, d, is a numerical measure of how alike or different two data objects, \(TCR_1\) and \(TCR_2\), are; \(\ s(TCR_1,TCR_2)=-d(TCR_1,TCR_2)\). Methodologies to assess similarity or dissimilarity rely on a distance measure, which in turn needs to be defined. Thus, the similarity is a function, that relies on the way distance between two data objects are defined; \(\ distance(TCR_1, TCR_2)\).")
Theory2 =("\chapter{Receptor Comparison: Protein conformation and comparison} In this second of three theory chapters, is a biological walk-through of the protein conformation of t-cell receptors and how they can be modeled and compared. \section{Protein conformation and modeling} Protein conformation is essential, as the structure of the protein is a determinant of function. The importance of protein conformation is illustrated by both defective protein folding and unfolded proteins - in the malfunctioning and deregulated state; these can promote, for instance, cancer development \cite{Wang2014TheDevelopment}.  Thermodynamic stability, hydrophobic interactions, and disulfide bonds determine protein conformation. Proteins are dynamic molecules that often can differentiate their conformations in response to binding \cite{Dill2008TheProblem.}. \subsection{Protein structure} Proteins are a product of the translation performed in the ribosomes based on mRNA relaying information in the form of bases. Three bases, a codon, become one amino acid (AA). When describing protein structure, there are four structural levels: the primary structure, secondary structure, tertiary, and quaternary structure. The word \textit{primary protein structure} is interchangeable with \textit{primary sequence}, as both are the amino acid residue sequence, e.g. MSSVLLGHI. This sequence does not relay any direct structural information, such as dihedral angles. Secondary protein structures are the structures resulting from the combination of residues and the dihedral angles between them. Secondary structures are, for example, helices, sheets, and loops. Tertiary protein structure is the arrangement of secondary structure elements within one protein chain. E.g. how the \(\beta\) chain have a \(\beta\)-sheet sandwich. The quaternary protein structure is the assembly of subunits into a protein complex. TCR has a quaternary protein structure consisting of the \(\alpha\) and \(\beta\) chain \cite{Williamson2012HowWork}. \caption[Protein structure levels]{A cartoon representation of the protein structure levels, figure adapted from OpenStax Biology's modification of work by the National Human Genome Research Institute.}Protein structure is determined either by X-ray crystallography or NMR spectroscopy. They both have some limitations. For instance, is the crystallography a static representation of a dynamic molecule, and NMR is only suited for small proteins up to 15 kDa \cite{Ramachandran2012HomologyMechanism}. Structures determined by either of these methods are \textit{solved structures}. The solved structures form the basis for structure prediction for other proteins, by acting as templates. Templates allow us to assess protein structure based on the primary sequence. Determining protein structure is necessary as solving the structures is a costly process, whereas predicting them is quite cheap \cite{Yang2018Sixty-fiveStretch}.Two methods form the basis of protein structure assessment. The first is a template method, while the second is a non-template method. The template method, homology modeling, relies on sequence alignment of homologous sequences, typically from position-specific substitution matrix calculated by an iterative Basic Local Alignment Search Tool (PSI-BLAST) \cite{Yang2018Sixty-fiveStretch}. The rationale is, that evolution has preserved essential functions \cite{Ramachandran2012HomologyMechanism}; however, it is widespread to remodel loops and refine the model with energy minimization. The alternative is the non-template method or ab inito. Ab inito is used when there is no relevant template available. The difficulty level rises with ab initio as a protein chain can fold into millions of different conformations. However, algorithms such as the one used in the Rosetta suite model can overcome this by the use of fragment libraries to model and by driving the structure towards a global energy minimization minimum when folding \cite{Kaufmann2010PracticallyYou.}. When modeling TCRs, it is possible to do homology modeling on the preserved framework, but it is wholly insufficient on CDRs, why these sites demand the usage of other measures.  While TCR structure can be predicted from the primary sequence by database comparison using blast to a high accuracy due to conserved regions, the CDRs cannot be structurally predicted with the same success, as they are hypervariable, and as it is generally difficult to model loops. Nevertheless, despite their difference in sequence, the CDR loops are each associated with a small number of distinct tertiary main-chain conformations; canonical structures \cite{Al-Lazikani2000CanonicalReceptors}. Thus, \textit{canonical structure} is a term describing the specific, limited, number of possible main chain conformational structures a CDR loop can assume. Although canonical structures are helpful in the structure of CDR1 and CDR2 loops, none can be assigned the CDR3 loop due to its high hypervariability \cite{Klausen2015LYRAModeling}. Proving the inability to assign canonical structure to CDR3 has been done by solving multiple structures for the same CDR3 sequence with no structural similarity \cite{Wong2019ComparativeReceptors}.The concept of canonical structures was first researched in immunoglobulins in the seventies and eighties when researchers observed that different loop sequences retained similar main chain conformation evaluated on the root mean square deviations. These conformations were primarily determined by the length of the CDR sequence and presence of key amino acids, that through packing, hydrogen bonding or the ability to assume unusual phi  (\(\phi\)), psi (\(\psi\)), and omega (\(\omega\)) angles to limit the main chain conformation \cite{Teplyakov2014CanonicalAntibodies}, \cite{Chothia1987CanonicalImmunoglobulins.}. The researchers were able to conclude, that the loops they observed in the solved crystal structures adhered to one of a small number of main-chain conformations \cite{Chothia1987CanonicalImmunoglobulins.}. These findings have been validated and refined since \cite{North2011AConformations}, why the canonical structure model is accepted as accurate. The utility of the canonical structures lies in the determination of the structural conformation based on primary sequence alone without the need to blast against an entire database or do the de-novo assembly. Avoiding to blast against an entire database greatly minimizes the computational workload and, therefore, has remarkable application. The fault of these structures is the fact that they are built on current knowledge and are continually updated as more structures are solved \cite{Wong2019SCALOP:Annotation} emphasizing one of the main issues within structural protein biology; no model is better than the data on which it was built. The quality and quantity of data is a dire problem, as the amount of TCR data available has been minimal for a long time. In 2000 Al-Lazikani et al. published a paper identifying three CDR1-\(\beta\) canonical structures and three CDR2-\(\beta\) canonical structures based on crystallographic structures of seven TCRs, two of which were human \cite{Al-Lazikani2000CanonicalReceptors}. Simultaneously, scientists found 25 canonical classes for the immunoglobulins for whom much more structural data were available \cite{North2011AConformations}. Yet, in 2016 \cite{Attaf2016Cross-reactivity} this framework was still used. North et al. published in 2011 \cite{North2011AConformations} a method to assign the canonical structures using an affinity propagation clustering algorithm (a type of clustering algorithm where the number of clusters is not pre-defined), which automates the process of assigning classes, and do not force a structure into a class to where it does not belong. As described above, consensus regarding the existence of several structural conformations is undeniable. However, continually the full extent of how many truly exist is re-evaluated. Klausen et al. \cite{Klausen2015LYRAModeling} utilized the affinity propagation algorithm when they developed the LYRA webserver in 2015. They naturally identified more canonical structures than Al-Lazikani et al. did in 2000.  At the time of writing this thesis, four canonical structures are available for CDR1-\(\beta\) and seven for CDR2-\(\beta\). \section{Comparison of Protein Structures} \subsection{Pre-defined Substitution Matrices} A comparison of primary structures of proteins is prevalent and forms the basis for alignment via the heuristic BLAST algorithm. Comparison and alignment generally rely on a substitution matrix that quantifies the change when two amino acids exchange position. Such quantification can be based on log odds ratio for each substitution possible \cite{Altschul1991AminoPerspective}, as seen in the most common alignment scoring matrix families; Blosum and PAM.Further, the substitution system includes a gap penalty when the sequences are not equal in length. The objective is often to maximize the score \cite{Edgar2009OptimizingAlignment}. The Blosum substitution scoring is based on a calculation of frequencies on sequences falling within a threshold of percentage identity. The blosum62 is perhaps the most commonly used scoring matrix, where sequences used to create the matrix had approximately 62 \% identity. The other family, the PAMs (percent accepted mutations), is based on substitution rates at closely related proteins and extrapolated for all other. A PAM10 matrix, for instance, accepts 10 mutations pr 100 amino acids \cite{Barlowe2017SubVis:Alignment}. Both of these are subject to inaccuracies. The matrices measure badly on non-conventional amino acid compositions \cite{Jimenez-Morales2008DetectingProteins.}, they have a hard time aligning distantly related sequences \cite{Prlic2000Structure-derivedSequences.}, they do not account for dynamics \cite{Wang2008APhylogeny.} and most importantly in this case: they do not incorporate structural information \cite{Vilim2004Fold-specificClassification.}, \cite{Goonesekere2008Context-specificHomologs.}. In attempts to gain further information from sequence alignment, researchers have tried to add evolutionary rate data \cite{Ndhlovu2015RobustMatrix} or include known motifs \cite{Dijkstra2018Motif-AwareRegions}. For instance, the JTT matrix, that is phylogenetic-specific \cite{Jones1992TheMatrices}. When aligning, more than just the substitution matrix is important; both the choice of local or global alignment and the underlying alignment algorithm are deciding factors. Here global alignment of the sequences in the case of CDR1, CDR2, and CDR3 is used. Using global alignment allows the ends of the sequences to be aligned, thus forcing the gaps to exist in the middle of the sequence. The gaps ensure sequence alignment in a fashion that is biological significant rather than maximized according to a scoring system. Furthermore, alignment algorithms include Needleman-Wunsch \cite{Needleman1970AProteins}, Gotoh \cite{AnSequences}, and Smith-Waterman \cite{Smith1981IdentificationSubsequences}. Both Needleman-Wunsch and Smith-Waterman rely on dynamic programming, while Gotoh is a superstructure based on Needleman-Wunsch. The Needleman-Wunsch algorithm, published in 1970, globally align sequences by dividing the task of full alignment into smaller segments in a grid. Hence, sequences are aligned by continually optimizing the score based on a substitution matrix and a gap opening penalty. The Smith-Waterman algorithm was published in 1981 and base the alignment on local sequence scores by setting all negative substitution scores to zero, which effectively allow more gaps and, thus, local alignments. Finally, the Gotoh algorithm was developed primarily to reduce the computational steps in the Needleman-Wunsch algorithm and to introduce affine gap penalty, meaning that it is not as costly to keep a gap open as it is to open it in the first place, consequently the gaps are larger and fewer with Gotoh alignment than with Needleman-Wunsch in principle. Hence, if a sequence should be aligned locally, the Smith-Waterman should be used. If alignment should be global, either Needleman-Wunsch or Gotoh can be used depending on the purpose. According to Barlowe et al. 2017 \cite{Barlowe2017SubVis:Alignment}, the biggest pitfall of using one substitution matrix instead of another is, that the utility is data-dependent, and how does one know which one is the best suited for one's data?  In other words: converting alphabetical characters denoting amino acids into numbers on which one can perform sophisticated statistics is not straightforward \cite{Atchley2005SolvingProblem}. \subsection{Alternatives to pre-defined Substitution Matrices}There are ways to quantify and measure, without a pre-defined matrix. One way is to create an ad hoc matrix, such as the position-specific substitution matrix, PSSM, where, as the name indicates, the substitution scores between amino acids depend on their position within the protein.  Construction of the PSSM is, therefore, dependent on the data input. Positive scores indicate that the amino acid substitution is more frequent in the alignment than it would have been by random chance \cite{Altschul1997GappedPrograms}. A Markov Chain, a statistic modeling tool, which incidentally lays the foundation for hidden Markov models, can be used to generate such a matrix \cite{MarkovBritannica}. Another way is the Atchley factors. The Atchley factors published in 2005, to solve \textit{the protein sequence metric problem} \cite{Atchley2005SolvingProblem} of numerically denoting the amino acids. Analysis of an abundance of attributes and clustering of the results lead to five physio-chemical variables.  Roman numerals indicate the variables or factors, and all five are attached to each amino acid. The factors include a polarity index, a secondary structure factor, molecular size, relative amino acid composition (how many codons are used to code it), and finally, a number for the electrostatic charge \cite{Atchley2005SolvingProblem}. The Atchley factors are pre-calculated for each amino acid, practically converting a letter into a vector with the five factors. Lastly is the k-mer approach, which is the most widely used alignment-free method, as the applications are vast. They work by dividing the sequences into k-mers (often 3, 4 or 5), and search for the k-mer frequency within the sequences analyzed. The rationale is that the repetition of k-mers indicates similar sequences \cite{Zielezinski2019BenchmarkingMethods}, \cite{Luczak2018AComparison}. While discussing physio-chemical properties, other measurements might be helpful such as measuring hydrophobicity or charge, where the logic is that proteins with similar hydrophobic attributes or charge will bind the same epitope. Hence, proteins can also be compared using Kyte & Doolittle index of hydrophobicity, where a positive value indicates a larger hydrophobicity. Traditionally this is done using a sliding window or as named above a k-mer. Nevertheless, when discussing only a domain of a protein, such as a CDR3 sequence, it might be plausible to consider the whole region \cite{Kyte1982AProtein}. Another physio-chemical property that has a grand effect on binding and allostery is the flexibility of the region. The flexibility can be measured with the amino acid b-values (atomic temperature factors), as there exists a correlation between average flexibility and a protein's thermal stability. Hence, higher thermal stability correlates to higher flexibility, which is interesting to measure in this case. It is interesting to compare the flexibility of the CDR3 sequences, to uncover if CDR3s that bind multiple epitopes have higher flexibility. However, all CD regions will inadvertently be flexible \cite{Vihinen1994AccuracyPredictions}.\subsection{Structural Comparison} To some extent, the PSSM and the Atchley factors include some structural information rather than being purely statistical tools. However, for structural comparison, other methods can be more suitable. Mainly root-mean-square-deviation (RMSD) and Template modeling score (TM-score). RMSD is a pairwise approach to compare molecules by moving and rotating one of the structures to superimpose the other and gaining knowledge of their difference by measuring the difference in the position of the aligned atoms \cite{Coutsias2019RMSDSymmetry.}. The most common unit used is Ångström (Å). If the structures are identical, the RMSD is zero Ångström. TM score uses a similar approach to RMSD but is adjusted to measure global fold similarity. It is less sensitive to local structural variations and is length independent. TM scores have a value between 0 and 1, where 1 indicate a perfect match \cite{Zhang2005TM-align:TM-score}, \cite{Xu2010How0.5}. ")
Theory3 =("\chapter{Mathematical Framework: Distance Metrics} In this last theoretical chapter, is an explanation of how to develop a distance metric, a characterization of the state of the art methods for TCR distance measurement, and finally, a description of their evaluation. A distance can be measured in a variety of ways, but it is always a function of two observations a,b, and their internal relationship.\section{Mathematical basis of a Distance Metric} Five fundamental criteria always need to be satisfied to have a distance metric as defined by R. Engelking in \textit{Outline of general Topology} from 1968 \cite{Birnbaum1979ThisPRESS}: \item Symmetry: The distance should be the same, regardless of it being measured from a to b or b to a, \(\ d(a,b)=d(b,a)\) \item Non-negativity: A distance cannot be negative, two points cannot be closer than identical, \(\ d(a,b) \geq 0\) \item Identification Mark: When measuring the distance to itself, it need always be 0, \(\ d(a,a) = 0\) \item Definiteness: A distance between a and b can only be zero if a = b. Definiteness needs to be seen in light of the context. As two TCRs might have the same genes and the same CDR3 sequence, which effectively would make them identical, but with different names. \item Triangle Inequality: The distance from a to b directly should be shorter than the distance from a to c plus c to b, \(\ d(a,b) \leq d(a,c) + d(c,b)\) Often it is sufficient if only the first three criteria are satisfied. The most simple way to measure distance is to quantify the magnitude of difference, yet then a and b are required to be numerical values that can undergo subtraction and get a norm \(\ d(a,b)=||a-b||\). Calculating the norm is not possible for protein structures without coordinates. Hence, distance measurements, quantification of amino acid components, and comparison of protein-structures are closely related. All methods to compare proteins can be defined as a distance with different units, such as Å for RMSD. The substitution matrices use a variation of the Hamming distance. A Hamming distance is a distance between two strings of equal lengths, meaning the number of times corresponding symbols are different. In the case of amino acid distances, these values are naturally, not binary, but dependent on the system used \cite{Bookstein2002GeneralizedDistance},\cite{Dash2017QuantifiableRepertoires}. Other commonly used distance measures are Euclidean distance, Gap-Hamming problem, Jaccard index, and Sørensen similarity index.  \section{Applied Distance-Measures} Accordingly, to develop a distance metric, the context of the protein structure, and how to compare these is the main task. However, these tools of comparison are not developed for t-cells only, why too much store should not be put on one single tool. Below is a description of the current state of the art distance measurements used within the TCR field. When evaluating these, two factors are important. Firstly, the distance needs to be biologically significant, and secondly, it needs to be computational light and fast. Therefore, it is somewhat a question of developing a metric that can differentiate for unknown epitope binding in the fastest way. Thus, be part of the framework for predicting epitope binding and, in extension, personalized medicine. \subsection{Applied distance-measures: Immunodist}Immunomap, developed in 2018 \cite{Sidhom2018ImmunoMap:Access}, is a tool for repertoire analysis  and does therefore have a way to measure distance. They do not present their distance measure with a specific name, but for the sake of simplicity it will be termed ImmunoDist here. This calculation uses an alignment matrix, PAM10 and employ a gap penalty of 30. Only the primary sequence of the CDR3-\(\beta \) loops is used. The alignment score calculated with PAM10, is written as \textit{PAM10} in the equation: \[\ ImmunoDist = \left(1 - \frac{PAM10(Seq_1,Seq_2)}{PAM10(Seq_1,Seq_1)} \right) * \left(1-\frac{PAM10(Seq_1,Seq_2)}{PAM10(Seq_2,Seq_2)} \right) \] A score of zero means the CDR3-\(\beta \) sequences are identical. The output is a matrix with all the TCRs in the dataset and their relative distance in positive numbers. \subsection{Applied distance-measures: GLIPH} Grouping of lymphocyte interactions by paratope hotspots, GLIPH, is an algorithm created by Glanville et al. in 2017 \cite{Glanville2017IdentifyingRepertoire}. The goal of the algorithm is to cluster TCRs based on binding specificity. Binding specificity clustering is achieved by clustering based on conserved motifs and global similarity of CDR3 sequences. The distance metric within this algorithm is based on a simple hamming distance and k-mer frequency. The input to the algorithm is CDR3-\(\beta \) and the V and J gene usage. However, distance is measured on CDR3 sequences alone. The algorithm can run on both \(\alpha \), and \(\beta \) data or \(\beta\) data alone, which is justified by the fact that CDR3-\(\beta \) always is in contact with the antigen, but CDR3-\(\aplha \) only is in contact often. The distance measurement follows the following steps: \item All CDR3 sequences are loaded, and unique sequences are counted  \item The Hamming distance is computed for CDR3s of the same length. The lowest distance for each is saved as a This is the minimum distance distribution for the data-set.\item A reference data-set is used to resample the test data and calculate new  hamming distances, creating a new distance distribution. The new distance distribution is made to asses how similar the data-set is, compared to a reference. Furthermore, to choose a Hamming distance cutoff. Using the distribution means that the similarity measure is dependent on the data itself, rather than being pre-defined. Which, in turn, answer the diversity question: how similar do two TCRs need to be,  to be the same species? It depends on the TCRs in the data-set and is defined on these.         \item The performance of this step, when evaluating clustering for specificity, is 12 \%, meaning that 12 \% of the TCRs are already rightfully clustered only based on Hamming distance.        \item The CDR3 sequences are converted into k-mers in IMGT positions 107-116. First, with k=3, then k=4 and k=5.         \item The frequencies of the different k-mers are calculated.        \item The data-set is again resampled to asses if the k-mers are enriched motifs. They need to be enriched a minimum 10-fold to be deemed a common motif. From this, a network is constructed illustrating the diversity using the Shannon entropy and Simpson's diversity. V-genes are used to analyze the resulting clusters by evaluating whether there is an enrichment of a common V-gene.  \subsection{Applied distance-measures: TCRdist}TCRdist is the distance measure developed by Dash et al. in 2017 \cite{Dash2017QuantifiableRepertoires}. TCRdist measures the distance between two TCRs by concatenating the hypervariable regions and quantifying the amino acids using an alignment metric, Blosum62, and adding weight to these observations. The input is, therefore, primary sequences of all CDRs both on the \(\beta\) and \(\alfa\) chains. Thus, it is a tool for single-cell analysis.\[\ TCRdist = \sum (Weight * AAdist) \]The weight is one for each amino acid in the CDR1 and CDR2 sequences for both the \(\alpha\) and \(\beta\) chain, while the weight is three for the CDR3 loops. The method employs a fourth loop termed CDR2.5, which too weight one. The biological position of this loop is unexplained in the publication. However, the only remaining loop on the TCR chains are the HV4 loop, so it is speculated if this is CDR2.5. Furthermore, this method is based on a pre-defined substitution matrix with defined gap penalties. The gap penalty in the CDR3 sequences is eight while being four for all other sequence segments. Contrary to most substitution matrix approaches, TCRdist should be minimized but can never be a negative number. The AAdist is defined as \(\ dist(Seq_1,Seq_1)=0 \), meaning a match is worth zero, and \(\ dist(Seq_1,Seq_2) = (4, 4-Blosum62(Seq_1,Seq_2)) \), meaning that a mismatch is four minus the value of the Blosum62 score. If \(\ 4-Blosum(Seq_1,Seq_2) > 4 \), the value is 4. The output is a matrix with all the TCRs in the data-set and their relative distances in positive numbers. \section{Metric Generation}When developing a model over-fitting is an issue, because a very complex model might describe a data-set perfectly, but is utterly useless to describe anything else. Hence, the model will face the bias-variance trade-off. In other words: the model should be as complex as possible without over-fitting. A large bias and a small variance will lead to poor approximation, but a robust model, e.g., the description of all data points are equally bad. Alternatively, a small bias and large variance, which will lead to good approximation but an unstable model, e.g., description of the training data points, are perfect. Still, the description of the test data is poor. Thus, the goal is to find the sweet spot of minimal complexity and lowest estimation error, judged on the test set.There are several ways to cross-validate model development; they all rely on training and testing data-sets, here three are presented: \cite{Yadav2016AnalysisClassification}, \cite{Ross2009Cross-Validation}:\begin{itemize}    \item Hold out \\    The data set is divided into two. A training set to develop the model and a test set to validate the model. The division is done as a small error on the training data will not imply small error on a randomly sub-sampled second set of data, the test data. Thus, ensuring that the model does not over-fit. However, the drawback of this method can be the validation error, as it can be misleading if an unfortunate split of the data had occurred. Hold out is the simplest way to estimate the validity of the model \cite{Yadav2016AnalysisClassification}.    \item K-fold and Leave one out \\    The data is divided into K partitions. Each partition is divided into a test- and a training set. K is the size of the test set, and the rest is the training. In leave one out, one data point is taken out of each run and used to validate. These methods are more computationally expensive than the hold out method \cite{Ross2009Cross-Validation}.\end{itemize}These can be nested within each other. For instance, the training set in the hold out method can undergo a K-fold validation, etc. The choice of the method relies on the size of the data-set. In a larger data-set, a hold out or perhaps a k-fold of 3 will suffice, while a smaller data-set might benefit from leave one out \cite{Yadav2016AnalysisClassification}.  \section{Metric Evaluation} Finding the model with minimal complexity and the lowest estimation error is a challenging task, why it is necessary to have tools to evaluate the outcome. In the simple end is a dendrogram based solely on pairwise dissimilarity. A more complex approach is to utilize similarity clustering and measuring the effect with the Rand Index and Receiver operator curve.  Dendrograms are visualizations of the internal relationship between the TCRs, based on the distance calculated by the distance matrix. Dendrograms allows the user to see the relationship hierarchy in a tree-like format, which is easier to interpret for the human eye. Further addition of a heatmap can make this interpretation even more accessible, allowing the user to spot closely related groups, based on denser coloring. Further, the dendrogram can also be the starting point for clustering approaches such as hierarchical clustering \cite{Artero2004UncoveringVisualizations}.Dendrograms are based on a metric, which calculate the distance between the TCRs and a method, which calculate the distance between clusters. Where clusters are partitions of TCRs, with similar characteristics \cite{Nugent2010AnBiology.}. The metric is in this case the distance measure but is most commonly the euclidean distance i.e. \(d(x_i,x_j) = ||x_i - x_j|| = \sqrt{\sum_{p}^{l=1}(x_il - x_jl)^2}\). The method on the other hand should be specified, and there is a number of options. These options include: begin{itemize}    \item Single linkage: A linkage method that relies on the distance between the closest member of each cluster.    \item Average linkage: A linkage method that relies on the average distance between all points in one cluster to all points in another cluster. \item Complete linkage: A linkage method that relies on the distance between the members of each cluster furthest apart, the opposite of single linkage. \item Centroid method: A linkage method that relies on the distance between the centroid of each cluster.    \item Ward method: A linkage method that relies on minimum variance within the cluster (only used in agglomerative clustering).\item Ward d2 method: Wards method, with the dissimilarities squared before clustering.This can, as mentioned, generate the foundation for hierarchical clustering by associating closeness groups based on the dendrogram. There are two main ways to do it, agglomerative and divisive. They are distinct by the clustering approach, while agglomerative begins from the bottom, presuming all branches as an individual cluster and merges branches to a cluster, the divisive way starts from the top and separates the further it comes down. When to merge and when to separate is based on the linkage method. Separating or merging continue until the reach of K clusters. K is a subjective choice based on a threshold set on the dendrogram \cite{Nugent2010AnBiology.}. Inserting a threshold might introduce bias and potential errors. Another way to cluster on similarity is affinity propagation. Affinity propagation is a clustering method, where each item, here distance, i, find another item, k, to represent it. The algorithm runs many iterations and, when terminating, generate clusters based on the chosen k's. Two main elements decide the clusters. The first being how much support there is for k to be a representative, how many i's find themself represented by k. The second is how fit k is to represent i compared to all other k's. Consequently, it is uncontrolled how many clusters are found - that depends on the data itself and the number of iterations \cite{Nugent2010AnBiology.}, \cite{Frey2007ClusteringPoints}. The clusters can subsequently be evaluated using the receiver operating characteristics and the Rand index. A cluster chart can make a visual representation of the separation on the data, yet the actual performance should be quantified as well. The rand index is a measure of agreement between the clusters found with a clustering algorithm and \textit{true} clusters defined by external criteria \cite{Rand1971ObjectiveMethods}. It is a number between 0-1, where 1 is perfect agreement. In this case, the epitopes or potential epitope groups define the external criteria while the distance matrix and subsequent clustering is the input. The goal is to generate a distance metric that, in turn, will produce a high rand index. Another way to quantify the clusters is to use the receiver operating characteristics (ROC) curve. The ROC curve arises from a confusion matrix with increasing thresholds. Hence, measuring the true positive rate and the false positive rate on the true and predicted conditions. Here true positives are the elements predicted to be in the correct cluster. Increasing the threshold will generate a number of points of the two rates, effectively producing a curve. The area under the curve (AUC) can be measured. It, too, is a number between 0 and 1, while 0.5 indicates a random partitioning of the data, and an AUC of 1 indicates a perfect partition of data \cite{Sonego2008ROCStructures}.")
methods = ("\chapter{Method of Developing a TCR Distance Metric} In the following section, the methods used to create the distance metric is stated. Firstly a description of data availability and how it will be partitioned to avoid over-fitting. This description is followed by two sections that will explain how the amino acid sequences of CDR1, CDR2, and CDR3 respectively will be converted into numerical values. Then how the distance metric will be constructed on these numerical values and, finally, how the distance metric will be evaluated, adjusted, and compared to state of the art.  It should be noted that python 3.6 was used as the platform for making the analysis and the metric. Packages or modules will be mentioned as they are used, as well as dependencies and deviations from the python 3.6 platform. Numpy and Pandas represent the basis of most calculations, while matplotlib for most of the basic visualizations, many of the packages used are dependent on these three. However, many of the illustrations are made in R. In this thesis, the word data refers to an amino acid or nucleotide sequence. These sequences are published along with the relevant publications and are for the majority of the relevant publications also published in a database such as VDJdb \cite{Shugay2018VDJdb:Specificity}, SRA \cite{Leinonen2011TheArchive} or Adaptive Biotechnology ImmunoSEQ site (http://adaptivebiotech.com). Publication to databases allows readily access.  For each publication, the sample sequencing platform, method of identification, and the epitope to which it binds is stated. However, the authors seldom describe the technique used to assemble the reads. Each of these variables has the potential to introduce biases. The most significant bias, however, comes from which epitopes have been studied. Therefore, a preliminary exploitative data analysis was conducted to justify potential threshold values and outlier removals, as well as sequencing platforms to ensure a suitable dataset on which to build the metric. \caption[Cross Validation Plan]{The data will be split into two, training and test. Three models are made on the training set, one in each fold. The models are validated using the remainder of the training set allowing measurement of estimation error, termed E. The best model is applied on the test set.} The data was split into a train and a test set, using a nested hold out method. The training set account for 80\% of the data, while the test set accounts for 20\%. The metric was developed on the training set and evaluated on the test-set. The data was not split entirely random but rather based on epitope similarity. The data was divided in such a way that each epitope only exists in one partition. Hence, a similarity metric of the epitopes was constructed, and TCRs binding similar epitopes put in the same partition. Furthermore, the training data underwent a 3-fold division in order to validate the method and avoid further over-fitting. Hence, the cross-validation is a nested K-fold, as seen in figure \ref{fig:nested_cross}.\section{CDR1 and CDR2} The V-gene determines the CDR1 and CDR2 sequences. The V-gene sequences are known. Hence, a library of gene sequences was constructed. Every known V-gene of the beta chain (TRBV) was extracted from the IMGT database \cite{Lefranc2014ImmunoglobulinImmunoinformatics.}. A total of 141 known alleles are listed with their name, sequence, and functionality. Eleven of these were pseudogenes. Pseudogenes are, for instance, genes with stop codons in the CDR sequences. Hence, IMGT supply a list of 130 functional sequences, which represent all known human TRVB genes. As mentioned, each of us expresses 52 of these. \subsection{Creating a Library of TCR structures} To allow structural and amino acid comparisons of the CDR1 and CDR2 loops, a library of sequences was constructed based on the IMGT database. The first five lines of which is illustrated in table \ref{table:2}.  gene library]{The format in which the V-gene library is constructed. Here only the first five of a total of 141 lines are illustrated. The sequences is translated to Amino Acids, the allele is the gene name in the format \textbf{T}-cell \textbf{r}eceptor \textbf{b}eta-chain \textbf{v}-gene and the functionality is the IMGT nomenclature} Based on these sequences extracted from IMGT, each TRBV gene was modeled. This was done by running the sequences through the LYRA algorithm \cite{Klausen2015LYRAModeling}. LYRA takes a fasta file as input. The file should contain an amino acid sequence of an \(\alpha\)- and a \(\beta\)-chain. Therefore all TRBV-genes were appended with a generic alpha-chain and identical non v-gene CDR3 sequence creating 130 fasta files. These were run through LYRA each outputting a \textit{.pdb} file.   When running all genes trough LYRA, the v-gene sequences are modeled into structures using the following steps: \begin{itemize} \item Canonical structure calculation: Sequence-based calculations dependent on residue positioning and length. The classification relies on a Hidden Markov Model. \item Loop grafting: Loop grafting is dependent on template selection. The template is selected among the templates with the correct canonical structures. Within this pool, the selection is dependent on a blosum62 score from the whole sequence plus a blossom62 score from the CDR1 and one from the CDR2 sequences. It is favorable to graft as little as possible. If the loops are grafted, the grafted sequence is superimposed on the framework to ensure correct positioning. \item Side chain modeling: For each residue not conserved between the template and the query, the sidechain is re-modeled using Scwrl4 \cite{KrivovProteinsSCWRL4}. \item Energy minimization: Finally, the model goes through 500 steps of energy minimization to avoid clashes using the ENCAD program \cite{Levitt1995PotentialSolution}. Thus, a library of TCR structures was generated. \subsection{Extracting the CDR1 and CDR2 structures} Each \textit{.pdb} outout from LYRA was trimmed using pymol \cite{PyMOLScripts}. Thus, creating two \textit{.pdb} files for each allele: a CDR1 and a CDR2 file. In the interest of a true structural comparison, one residue from the framework on each side of the CDR1 and CDR2 sequence was kept when trimming. As seen in figure \ref{fig:mesh5} this is done to ensure that the subsequent superposition of structures does not only mathematically optimize but still retain its appropriate position within the t-cell receptor, making structural comparison possible.\subsection{Assigning structural distances between the structures} RMSD and TM-score was obtained on the trimmed \textit{.pdb} files. The RMSD was calculated using the biopython module \cite{Hamelryck2003PDBPython}, \cite{Iserles1990MatrixComputations}. while TM-score was calculated using TM-align \cite{Zhang2005TM-align:TM-score}. These scripts further rely on Minuit \cite{James1975MinuitCorrelations} and glob packages. As the goal is to calculate a distance, the smallest number must be the shortest distance. The TM scores were transformed as 1-TM scores to satisfy Engelking's first rule in distance measurements. Moreover, RMSD was scaled after all calculations were finished, so the largest RMSD became one, and all other pairs were scaled using this maximum. This method generated four .csv files, two for CDR1: a 1-TM distance matrix and an RMSD distance matrix. And two CDR2 files: a 1-TM distance matrix and an RMSD distance matrix. These distance matrices are descriptions of the main-chain conformational differences and will be evaluated on subsequent performance.\subsection{Sequence comparison for CDR1 and CDR2} The sequence library used to generate the structural comparisons are reformed to a \textit{.csv} file with three columns: gene names, CDR1 sequence, and CDR2 sequence. They can then be imported for comparison using a sequence comparison tool. This is interesting as the structural comparison only compares the main chain conformations rather than also comparing sidechains. These sequence comparison tools are converted to a distance measure by scaling to a 0-1 matrix and subtracting from one if the objective of the comparison tool is to maximize the score. Scaling is done after all calculations have been made, as it then is possible to know the max and minimum scores and not lose any information. Due to the relatively low amount of data, these matrices can be pre-computed, normalized, and imported as a dictionary. It was decided to choose one physio-chemical parameter and one alignment tool to describe the CDR1 and CDR2 side chain, Kyte and Doolittle's Hydrophobicity scale \cite{Kyte1982AProtein} and Blosum62. Blosum62 due to its broad acceptance and utility. Hydrophobicity due to a higher rate of immunogenic responses in hydrophobic CDRs \cite{ChowellTCREpitopes}. Which is paramount as a drug target. The decision to include four metrics was based on the assumption that structural information would be the most important, while still wanting to include both an alignment method and a physio-chemical parameter.\section{CDR3} When comparing CDR3 sequences, two categories of tools are used: Pre-defined substitution matrices and alternatives. For the pre-defined substitution matrix, Blosum62, Blosum45, Pam10, and the simple Hamming distance is chosen as representatives. They are chosen due to their broad utility and current use in TCR comparison \cite{Dash2017QuantifiableRepertoires}, \cite{Thakkar2019BalancingSimilarity}, \cite{Sidhom2018ImmunoMap:Access}, \cite{Glanville2017IdentifyingRepertoire}. The second group, alternatives, are k-mers, Atchley factors, hydrophobicity, and volume. K-mers are chosen based on their current TCR comparison usage \cite{Glanville2017IdentifyingRepertoire}. Atchley factors, hydrophobicity and volume are chosen to include physicochemical properties \cite{Atchley2005SolvingProblem}, \cite{Kyte1982AProtein}. These eight methods were chosen to test a broad fan of options from all schools of comparison, excluding structural similarities. Current techniques do not allow useful structural comparisons of CDR3s. The tools are selected based on their current use in comparing TCRs.\subsection{Sequence comparison for CDR3}When comparing the sequences of the CDR3, the scores need to have the same objective. Therefore, they need to be scaled. Two ways of scaling are used. When aligning, gap penalties are used as described below in agreement with publications on TCRs, however, often gap extend penalties are not reported why 0.5 will be used in all alignments.For the substitution matrices, the score is normalized based on equation \ref{eq:1}. New_{Score} = \frac{Score(seq1,seq2)}{x(Score(seq1,seq1),Score(seq2, seq2))} \end{equation}Where x is either minimum or maximum. Secondly, when a \textit{own score} between two sequences does not apply, the scores are normalized using equation \ref{eq:3} New_{Score} = \frac{(old value - old min)*(new max-new min)}{old max - old min} + new min  \end{equation} The new max is always one and the new min always zero.Normalizing is done to compare and combine parameters. As the different parameters are vastly different and normalizing after summing over tools where some give a score of 50 and others a score of 0.4, the information gain in the tools with the lower scoring system will be lost. Secondly, scaling cannot be done after each tool has generated a matrix, as this would put considerable strain on the computational load.  It follows that the scaling needs to be done simultaneously with the calculations. Therefore, to ease the computational load and avoid calculating three values to compare two TCRs, a diagonal with each self-score is calculated and loaded in as a dictionary. Given the objective of the original function, maximizing or minimizing, the scaled score will either be a similarity or distance score, why some may be subject to 1-new value. These algorithms are available in appendix 1. The hamming distance is adapted to give the score 0 for a match and a score of 1 for a non-match. The difference in length is considered a non-match. The range of the Hamming distance is, therefore, zero to the maximal length of the CDR3 region. To overcome this the maximal length of the CDR3s in the dataset is used: \[Hamming_{distance} = \frac{(Hamming_{score}-0)*(1-0)}{Max Hamming_{score}-0 }+0\ \[Hamming_{distance} = \frac{Hamming_{score}}{Max length of CDR3}\]     \item Blosum62 alignment \\     Blosum62 scores match and non match in the range -5 to 11. Where a higher score indicates more similar sequences. Hence the new values is adapted from equation \ref{eq:1} as: \[Blosum62_{distance} = 1 - \frac{Blosum62(Seq1,Seq2)}{max(Blosum62(seq1,seq1),Blosum62(seq2, seq2))}\]. The Alignment in the biopython module is done with global alignment and the Gotoh algorithm with a gap penalty of 8, as done by Dash et al. \cite{Dash2017QuantifiableRepertoires}.  \item Pam10 alignment \\      The same logic is applied to the pam10 which have scores ranging from -23 to 13. And can be scaled based on equation \ref{eq:2}       \[Pam10_{distance} = 1 - \frac{Pam10(Seq1,Seq2)}{max(Pam10(seq1,seq1),Pam10(seq2, seq2))}\] The Alignment in the biopython module is done with global alignment and the Gotoh algorithm with a gap penalty of 30, as done by Sidholm et al. \cite{Sidhom2018ImmunoMap:Access} \item Blosum45 alignment \\      Blosum45 scores are in the range -4 to 15. Where a higher score indicates similar sequences. Hence the new values is adapted from equation \ref{eq:1} as: \[Blosum45_{distance} = 1 - \frac{Blosum45(Seq1,Seq2)}{min(Blosum45(seq1,seq1),Blosum45(seq2, seq2))}\]. The alignment in the biopython module is done with local alignment and the Gotoh algorithm with a gap penalty of 10. The scaler is the minimum score. The local alignment and minimum scaler were done to mimic Thakkar and Bailey-Kellogg 2019, \cite{Thakkar2019BalancingSimilarity}. It is justified to make a local alignment and minimum scaling, as this is the second Blosum scoring matrix, why it does not change the whole framework. \item K-mer \\The CDR3 sequences are divided into k-mers of length k, and the similarity is calculated using the Jaccard similarity. The distance 1-Jaccard giving a pairwise score between 0 and 1, why scaling is superfluous. The K's that will be researched are k = 3, k = 4 and k = 5 \item Athcley factors \\ The amino acids in the CDR3 sequences are compared using the Euclidian distance between the Atchley factors and generate a numerical value where 0 is identical, and 5 is the highest level of difference, why this too needs to be scaled. In this case, the scaling is based on empiric evidence after comparing 11.000 TCRs, the highest score was 4, which become the scaling factor.  \[Athcley_{distance} = \frac{(Athcley_{score}-0)*(1-0)}{Max Athcley_{score}-0 }+0\] \[Athcley_{distance} = \frac{Athcley_{score}}{4}\] \item Kyte and Doolittle hydrophobicity scale \\  Hydrophobicity is rephrased as a distance metric by finding the difference in the total hydrophobicity of two CDR3 sequences and scaling it. Here the logic is that similar sequences in terms of hydrophobicity will bind similar epitopes. However, the position of the hydrophobic residues is not taken into account. Again scaling is based on empirical evidence, and the highest score was 2.5, why this becomes the scaling factor. \[Hydro_{distance} = \frac{(Max Hydro_{score}-Min Hydro_{score})*(1-0)}{Max Hydro_{score}-0 }+0\] \[Hydro_{distance} = \frac{CDR3_{Max hydro} - CDR3_{Min hydro}}{2.5}\]item Zamyatnin's volume in solution scale \\Amino acid volume is rephrased as a distance metric by finding the difference in the total volume of two CDR3 sequences and scaling it. Here the logic is that sequences that are close to each other in volume will bind similar epitopes. Again, the position of the residues are not taken into account. Scaling is based on empirical evidence, and the highest score was 1300, why this becomes the scaling factor.\[Volume_{distance} = \frac{(Max Volume_{score}-Min Volume_{score})*(1-0)}{Max Volume_{score}-0 }+0\]\[Volume_{distance} = \frac{CDR3_{Max Volume} - CDR3_{Min Volume}}{1300}\] \end{itemize} \end{itemize}The testing of each of these parameters, both individually and in combination, is performed. The best performing combination is measured on how well the epitope is predicted and the used computational power.  \section{Distance Metric} The distance measure between two TCR beta-chains is thus a function over the distances of CDR1, CDR2, and CDR3 with weights attached to the different methods. The distance measure is trained on a dataset, and should for further application generate a distance matrix with all pairwise distances between the input TCRs. Therefore a wrap around script is created to allow parallel processing of these calculations. \subsection{Mathematical Framework} The framework for the distance measure, d, between two TCR-\(\beta\) chains \textit{i} and \textit{j} can simplified be described as the following equation: \end{split}\end{equation}Lambda is the weight given to each method. Assigning such a weight is sought done with logistic regression due to the binary nature of the problem. Other parameters, such as other distance methods are also tested as weights. The structure comparison is RMSD or TM-score while the sequence comparison is as described in earlier, Sequence comparison for CDR3. Furthermore, equation \ref{eq:2} is represented as a sum, however, this is dependent on the results. \subsection{Algorithm Framework} To encompass all the described elements, the architecture of the needed algorithm is planed, as shown in figure \ref{fig:code_frame}. The input is a tab-separated file containing three strings for each row. A CDR3 sequence, the V-gene in IMGT nomenclature, and binding epitope. The V-gene is recognized, and the pairwise distances are fetched from a library imported as a dictionary. The CDR3 sequences are pairwise compared using one or more of the methods. Finally, the mathematical framework is imposed on these scores, and the output is a distance metric in a matrix format. The epitopes imported in the beginning is used at the evaluation state after the core algorithm has run. \begin{figure}[h] \includegraphics[width=\textwidth]{graphics/Methods/code_workflow} \caption[Algorithm Framework]{A schematic representation of the principal steps in the algorithm.} \subsection{Performance evaluation} The performance of each method is evaluated based on 1) how well it predicts if two TCRs bind the same epitope 2) how well it allows clustering of specific epitopes and 3) how fast it runs. To evaluate how well a method predicts if two TCRs bind the same epitope, two binary files are generated of the same size as the distance matrices for each method. The first is based on an exact match between Epitope and HLA genes. Hence the binary file has 0 as negative when the two TCRs do not bind the same epitope presented on the same MHC, and 1 when it does. An example is presented in fig \ref{fig:bin_exact}. The other binary file is based on epitope similarity, and allow very similar epitopes and epitopes bound on different MHCs to be identified as positives, as presented in fig \ref{fig:bin_group}. These two files are achieved based on string identity, and a library imported dictionary. Hence, there is a truth matrix to which to compare. \begin{figure}[h] \includegraphics[width=\textwidth]{graphics/Methods/exact} \caption[Binary comparison output for exact matches]{A small part of a potential binary matrix with exact matches, only a perfectly identical binding gives a match.} \centering \end{figure} \begin{figure}[h] \includegraphics[width=\textwidth]{graphics/Methods/group} \caption[Binary comparison output for grouped matches]{A small part of a potential binary matrix with grouped matches, closely related bindings gives a match.} After each distance is calculated, they are compared to these binary files. This is done by imposing a threshold vector. The threshold vector is determined by the fractions of the underlying distance distribution, as calculated by sklearn.metrics \cite{Pedregosa2011Scikit-learn:Python}. The comparison is made along this threshold as the logic of the distance metrics dictates that a short distance between two TCRs would suggest the same binding. Therefore the distance matrices are evaluated at each quantile in the threshold vector. For instance, at \textit{t}=0.10, will be the distance, \textit{d}, at which one distance metric has explained the first 10\% of the data. Here all distances in the distance matrix of distance \textit{d} or below is converted to positives (1) and the rest is converted to negatives (0), this new matrix is compared to the two binary files which in turn make it possible to calculate the confusion matrix at each of these distance thresholds. %To avoid generating and saving many huge files and thereby making a program that cannot be scaled to larger datasets, the algorithm takes a smaller subsection of the data and compare it to the same small subsection of the binary data, only saving the confusion matrix. The confusion matrixes are later summed at each threshold. Based on these confusion matrices, the true positive rate and false positive rate of each method can be calculated. This is used to generate a ROC curve. The ROC curve is a visualization as well as a quantitative tool of the classifier quality. To achieve a better classifier than one method alone, they are combined. To determine which methods are good classification tools, logistic regression was applied to the distance matrices. However, the dataset is imbalanced as the binary matrices that contain the information of whether two TCRs bind the same epitope have a vast majority of negatives (0) and a vast minority of positives (1), why doing logistic regression on the dataset as it is, is improper \cite{Zhao2007ProteinData}, \cite{Ohsaki2017Confusion-matrix-basedClassification}.The problem with an imbalanced dataset, where the majority is negative, is that if every case is classified as negative, the accuracy of the model will be very high, as most cases by far are negative. Nevertheless, no real information gain has been achieved. Therefore it is necessary to even out the imbalance. There exist several ways to solve the imbalanced data problem; they can be divided into three groups: the algorithmic approach, data-preprocessing approach, and feature selection approach \cite{Oommen2011SamplingRegression}. In this case, the data-preprocessing approach was used. The data-preprocessing approach is a way to balance the dataset before classification, by either upsampling the minority or downsampling the majority group. In the interest of keeping the file sizes down and running, the downsampling of the majority group is conducted. Hence, each line of the distance matrices is read and reformed into a data frame where each method is a column, and the column contains the distance to one TCR. The last column is the binary file informing if there is a match. Each match is kept, and the same number of non-matches are kept, using sklearns resample \cite{Pedregosa2011Scikit-learn:Python}, thereby making a balanced set. There is looped over every line in all files, while it is only the resampled set that is kept. Naturally, the risk of this approach is a potential loss of valuable data. Alternatives to this approach include feature selection, which does not fit the aim of the thesis, as the features have been carefully chosen. Finally an algorithm such as kernel logistic regression or maximum-likelihood logistic regression (MLLR) \cite{Maalouf2011RobustData}, \cite{Oommen2011SamplingRegression} could also have been used. Yet these, too, rely on subsampling at their core, and there does not seem to be any particular method accepted as state of the art. Hence, balancing the data is kept simple and with regard to disk space and calculation time. Logistic regression is performed on this resampled set. Thus, the evaluation of performance is done individually firstly. The worst performing elements are removed, and the remainders combined and assigned coefficients. The best performing model is applied to the test-set.  \section{Performance comparison}The performance of the developed TCR distance will be compared to all the methods added together and the current state of the art. This is done by downloading the source code of state of the art via GitHub and running the test data through these. Then evaluate the same parameters as described above. Although, some codes do not run smoothly, why some changes have been made, as described below. \subsection{Immunomap}Immunomap is written in MatLab but translated into a python script to run within the same framework. The alignment algorithm used to align on the Pam10 is Needleman-Wunsch \cite{Sidhom2018ImmunoMap:Access}, yet the biopython module has been used, applying the Goroth algorithm, which is not in compliance with the original Immunomap distance measure. However, a test was run to asses the difference in the biopython-Goroth and Matlab-Needleman-Wunsch performance. This test included 22 CDR3 sequences, which underwent respectively biopython-Goroth and Matlab-Needleman-Wunsch alignments and was subsequently subject to the Immunomap scaling and scoring method. Hence, it was found that in the 484 scores in the total distance matrix, 78 scores were different, meaning 16\% of the scores varied. However, the numeric variation was minimal; the total percentage deviation within these 78 scores was 4.9\%. Hence, it is justified to use biopython-Goroth, yet a small error is introduced. \subsection{CDRdist}The code is not available for CDRdist. However, the similarity metric is very simple and can therefore be applied within a reasonable certainty that it is true. However, the smith waterman alignment tool they used have become obsolete, the last minor update in their github was four years ago - it is not compatible with python 3 or above. Hence, skbio's python implementation of Smith-Waterman alignment have been used. Naturally CDRdist have been converted from a similarity measure to a distance by subtracting from one.\subsection{GLIPH and TCRdist} GLIPH and TCRdist is both written in python, but neither will be used for comparison. GLIPH because the output is not a distance metric, but a list of enriched k-mers and an assessment of each CDR3. Hence, converting these information into a distance metric and making a psudo-GLIPH will stray far away from the intented use, why GLIPH have served as inspiration for the metric presented here rather than a direct comparison metric. For TCRdist, it was written in an older version of python and cannot be run directly without making changes to the code. Therefore the code is not in total compliance with the original code. Furthermore, TCRdist is a complete TCR tool that compares both \(alpha\) and \(beta\) chains. Hence, comparing to half a pseudo-tool might not be sustainable, and definitely does not do them justice. Furthermore, the alignment algorithm is not specified in the article, why comparison will introduce bias.  ")
results1  = ("\chapter{Analysis of T-cell data to develop the Distance on} This chapter is the first of three chapters presenting the results of this thesis, on the following pages is a presentation of the initial data analysis. This presentation seeks to gain insight into the chosen data-set and to use the gained knowledge to determine data division. The first section describes the origin of the data. The second section is the preliminary analysis of the TCR and MHC binding. This analysis is conducted by examining and presenting gene usage, both for the TCR and MHC, as well as epitope binding, epitope species, and TCR promiscuity. The third section is a section concerned with the quality of the data. Here filtering and clean up are presented, stating exclusion parameters and filtering out unsuitable data. The last section of the chapter displays how the data was separated into a training-set and test-set ready for the distance metric analysis that will be presented in the subsequent chapters. \section{Sequencing and Identification Methods} \begin{figure}[h] \includegraphics[width=\textwidth]{graphics/Results_1/pipeline} \caption[Sequencing and Identification pipeline]{General overview of the pipeline needed for a sample containing TCRs are sequenced and uploaded to a database. Figure is icons from word.} \caption[Laboratory Methods]{Piecharts depicting the distribution of the origin of the data and how it was procured and sequenced before uploaded to the VDJ database, hence the first three steps of figure \ref{fig:pipeline}. The leftmost piechart illustrates the origin of the TCRs. The middle piechart illustrates how the TCRs were identified. Body fluids are blood, Lymph, and Synovial Fluid. Organ tissue is lung, spleen, and tonsil. The rightmost piechart illustrates the sequencing instrument used to sequence the data.}\centering\end{figure}The data was collected from the VDJ database \cite{Shugay2018VDJdb:Specificity}. All human data was downloaded in a tab-separated file on the 12th of December 2019, and all data deposited in the database since then is not included. In appendix 2 is a list of the publications where the data was published. The TSV file contained 61.483 chains, of which 39.302 were \(\beta\)-chains. The file was sorted based on the VDJdb confidence score, which is a measurement of the sequencing quality and binding specificity. All scores below one were removed from the data, and thus, 4346 TCR \(\beta\)-chains remained in the data-set. These \(\beta\)-chains lay the foundation for the following analysis. The purpose of the VDJ database is to collect data from multiple sources, why the analysis of these sources is essential. Firstly one should consider how different labs use different protocols and equipment both to sample, identify, and sequence. The goal is to have a broad spectrum of sample origin, identification methods, and sequencing platforms to avoid systematic errors resulting in a biased tool. Hence, to start from the beginning following the structure of figure \ref{fig:pipeline}: TCR origin in the data-set is summarized into four categories; Cultured T-cells, T-cells from organ tissue, T-cells from body fluids (mainly primary peripheral blood) and not reported. The binding specificity was determined in 35 ways, mainly using multimer sorting. Three specific multimer sorting methods were used more commonly than the rest: \textit{tetramer sort}, \textit{dextramer sort}, and \textit{antigen-loaded-targets}. Using tetramer sort is, as the name indicates a procedure, where tetrameric proteins detect T-cells binding a specific epitope. The tetrameric proteins are MHC molecules bound to the relevant epitope and labeled. The tetramers are labeled and washed over a surface of T-cells, hence the detection of TCRs that bind. The TCRs that bind are subsequently analyzed. \cite{Altman1996PhenotypicLymphocytes}, \cite{Dolton2015MoreMultimers}. Dextramer sort types are also MHC multimers, like the tetramer, which is MHC molecules attached to a dextran backbone and is superior in finding binders due to improved specificity and signal-to-noise ratio \cite{Bakker2005MHCProspects}. There is no indication that the identification method should be an exclusion criterion.After identification, the data was sequenced using a sequencing platform. Sanger is a first-generation method which is low-throughput, costly, and inaccurate. Amplicon seq and Ilumina are second-generation methods; they are PCR mediated, Relatively cheap, but introduce bias primarily in the choice of primer. RNA-seq is a next-generation sequencing method, which is good at catching mutations (such as found in junctional diversity). However, it introduces problems when the sequencing depth is insufficient. The most common method in this data-set is sanger.It should be noted that these sequences often have been validated, why they are of good quality, according to VDJdb. If all sequences are included, the most common sequencing platform is RNS-seq, which also illustrates that the market for sequences is increasing exponentially. As there are problems and uncertainties with each of the platforms, there is no reason to discriminate against a particular platform for further analysis. The fourth step in figure \ref{fig:pipeline} is read assembly into TCR \(beta\). There is no report of sequencing depth or assembly methodology in the database. Hence, no knowledge of the quality of the final assembly is known. Therefore, sequences that are quite different from the ordinary can be a product of lousy sequencing, and removal considerations should be taken into account in such cases \cite{Schirmer2015InsightPlatform}, \cite{Williams2014RNA-seqAnalysis}. However, when sorting based on VDJdb scores, most lousy data is already removed, which is evident when comparing the entire set of almost 40.000 to this curated subset. \section{TCR:MHC binding}As the CDR1 and CDR2 primarily determine the TCR binding to the MHC, the V-gene usage was inspected. The distribution can be seen in figure \ref{fig:gene_distrib}; here, it is evident that the most common V-gene usage is TRBV-19. Common TRBV-19 usage is consistent with findings by Marrero et al. in 2013 \cite{Marrero2013High-ThroughputMice} and Chen et al. in 2017 \cite{Chen2017Sequence5E6I} who empirically have found that TRBV-19 was more prominent conserved than other V-genes. Song et al. argued in 2017 \cite{Song2017BroadEpitope} that this is due to the preference of binding TRBV-19 to HLA-A*02, which is a very abundant HLA gene \cite{Gonzalez-Galarza2015AlleleAssociations}. The TRBV-19 preference to HLA*02:01 is visible in the data-set, as shown in figure \ref{fig:gene_distrib}. Furthermore, it is evident that HLA-A-02 is the most prominent MHC gene in the data-set \cite{Song2017BroadEpitope}, \cite{Turner2005LackPopulations}.  Finally, the chord diagram in figure \ref{fig:gene_distrib} illustrates how there is not a pairwise binding between specific  V genes and HLA genes even though there can be preferences. Both the MHC molecules present epitopes to the TCRs, yet, the distribution of MHC class I and MHC class II represented by the data is not equal, 92.3\% of the data comes from MHC class I bound TCRs. The length of these epitopes depends, as expected, on the MHC type on which it is presented. A mean length of 9.26 for all presented by MHC class I and a mean length of 16.4 for all presented by MHC class II.   \begin{figure}[h] \includegraphics[width=\textwidth]{graphics/Results_1/HLA+Vgene} \caption[V-genes & HLA binders]{Illustration of the gene distribution and binding. The top bar chart illustrates the HLA genes to which the TCRs bind. The y-axis is the number of times each HLA is bound in the data-set. The bottom bar chart is an illustration of the distribution of V-genes encoding the CDR1 and CDR2 in the data-set. The chord diagram illustrates the V-genes on the bottom and the HLA to which they bind on the top. Illustrating the MHC-CDR1/CDR2 binding. The TRBV-19 to HLA-A*02, binding is pointed at with the red lines. However, it is evident that there are multiple HLA binders to each V-gene. Figure is made with R, standard for barplots and circlize, migest and dplyr libraries for the chord diagram.} \label{fig:gene_distrib}\centering \end{figure}The next part of analyzing the TCR:MHC binding is the binding between the epitope and CDR3s. The 4346 \(\beta\)-chains are distributed over 140 epitopes and display 2847 different CDR3 sequences. The distribution of the TCRs to the different epitopes can be seen in figure \ref{fig:epitopes}. On average, each epitope is bound by 31 TCRs, however with a standard deviation of 62 - many epitopes are only represented by one TCR. Sparsely represented epitopes can lead to some errors in the model. There is a risk that other TCRs in the data-set does indeed bind these epitopes and reverse, that these TCRs bind other epitopes in the data-set - as the data is limited by which epitopes have been tested against which TCRs. As the hypothesis state that a group of TCRs binding the same epitope should have a shorter distance to each other than to the TCRs binding other epitopes, epitope groups of TCRs that only comprise one TCR become a tiny cluster - unless there is cross-reactivity. Where it in this distance metric evaluation will count as an error.\ref{fig:gene_distrib}. \begin{figure}[h]\includegraphics[width=\textwidth]{graphics/Results_1/epitope_distrib}\caption[Epitope distribution]{The distribution of epitopes based on the TCR frequency, how often a TCR bind each of the epitopes. Barplots made in R.}    \label{fig:epitopes}\centering\end{figure}The epitopes belong to species, and in this data-set, the 140 belong to one of 12 species of pathogens. These epitope species are listed in table \ref{table:2}. Here it is also represented how many of the epitopes from figure \ref{fig:epitopes} are present within each species.  Further, table \ref{table:2} lists how many of the TCRs belong to each of the species. Table \ref{table:2}  gives an overview of the origin of the epitopes in the data and another way of showing distribution.  \begin{table}[h!]\centering\begin{tabular}{  m{20em} | m{2cm}| m{2cm}  } \hlineEpitope Species & Epitopes & TCRs \\ \hline\textbf{Autoimmunediseases} &  &  \\Human immunodeficiency viruses (HIV-1) & 38, 27.14\% & 1250, 28.76\% \\\hline\textbf{Cancers} &  &  \\ Homo Sapiens & 21, 15.0\% & 99, 2.28\%\\Human T-lymphotropic virus (HTLV-1) & 8, 5.71\% & 55, 1.27\%\\\hline\textbf{Infectious diseases} & & \\Influenza A & 10, 7.14\% & 517, 11.90\% \\Dengue Virus (DENV1, DENV2, DENV3/4) & 3, 2.14\% & 135, 3.11\% \\Hepatitis (HCV) & 6, 4.29\% & 385, 8.86\% \\Yellow Fever (YFV) & 1, 0.71\% & 28, 10.644\%\\Cytomegalovirus (CMV) & 22, 15.7\% & 932, 21.45\% \\Ebstein-Barr virus (EBV) & 24, 17.14\% & 868, 19.97\%\\Herpes (HSV-2) & 1, 0.71\%& 68, 1.56\%\\\hline\textbf{Others} & & \\Bakers Yeast: Saccharomyces Cerevisiae & 1, 0.71\% & 1, 0.0023\% \\ Common weat: Triticum Aestivum & 5, 3.57\% & 8, 0.18\% \\ \end{tabular} \caption[Data distribution on Epitope species]{Table presenting the different epitope species and their distribution on epitope and total amount of TCRs from the downloaded Human dataset from VDJ. The first column name the epitope species, the second column count the epitopes within the species and report the percentage of the total number of epitopes. The third column report the number of TCRs within each epitope species and the percentage of total TCRs} To further describe the TCRs and their relation to epitopes, one must describe the CDR3s present. The length distribution can be seen in figure \ref{fig:length}. Here it is evident that the CDR3s are distributed around 14.3 and have a standard deviation of 1.7 - the CDR3s are in general relatively uniform in length apart from a very few outliers. Furtheremore,when seperating CDR3 length into two sections, all that bind MHCI and all that bind MHCII. Here it is also evident that the mean length of the CDR3 regions does not influence binding to epitopes in the MHC groove. There is no coorelation between epitope length and CDR3 length.\begin{figure}[h]\includegraphics[width=\textwidth]{graphics/Results_1/length}\caption[Length distribution of CDR3- and Epitope Sequences]{CDR3 length is crucial to structure and binding, as a longer CDR3 has a larger surface area, yet they are not related to the length of the epitopes. the barcharts illustrate the distribution of length of the Epitopes in amino acids. Presentation by either MHC class I or class II is indicated with grey and black respectively. Barplots made in R.}\end{figure} The last element to consider in TCR:MHC binding is the promiscuity of the TCR. In the data-set, 2777 of the 2847 unique CDR3 sequences bind only one epitope. However, the remaining 2.5\% (70) of unique CDR3s do bind to more than one epitope. The majority, 59 CDR3s, bind two epitopes, and the number of CDR3s capable of binding multiple epitopes decreases exponentially with an increased number of binders (five CDR3s binds three epitopes and four CDR3s binds four epitopes. Interestingly two CDR3s bind nine epitopes, illustrated in figure \ref{fig:seqlogo}). It is of interest to know if the epitopes one CDR3 binds are similar, as similar epitopes would indicate that a similarity metric based on TCRs could have some predictive power. To examine this sequence logos can be generated. However, as the sequence logos themself does not hold any quantitative power. Nevertheless, to illustrate motifs in these bindings, two are displayed in figure \ref{fig:seqlogo}. Here there seem to be clear motifs for these two CDR3s. Despite other CDR3 multi-binders bind epitopes as different as 'QVPLRPMTYK' and 'HPVGEADYFEY'.  Finally, it should be noted that all of the TCRs in the data-set might be promiscuous, yet their other binders are just not present in the current data-set. To analyze this phenomenon, firstly, the flexibility of the promiscuous CDR3s are examined, with the hypothesis, that more flexible chains can bind more epitopes. Flexibility was measured using the CDR3 length and the framework developed by Vihinen M. et al. in 1994 \cite{Vihinen1994AccuracyPredictions}, which take the residues into account. On both accounts, there is an indication that these parameters might be interesting to reconsider on a larger data-set, yet, no conclusion can be drawn to the end of this hypothesis.\includegraphics[width=\textwidth]{graphics/Results_1/9_2}        \caption[CASRPGLAGGRPEQYF]% {{\small The sequence logo of the eight epitopes bound to CDR3 sequence \textit{CASRPGLAGGRPEQYF}}} \end{subfigure} \caption[Sequence logos for Multiple epitopes bound to one CDR3 sequence] {\small The Sequence logos presented are created by aligning the Epitope sequences with the biopython package in python using the Multiple Sequence Comparison by Log-Expectation algorithm (MUSCLE) \cite{Edgar2004MUSCLE:Throughput} and Berkleys Weblogo platform \cite{Crooks2004NCBIGenerator}, \cite{Schneider1990SequenceSequences}. The figure illustrate that some CDR3s, have a clear binding motif in the data.} \label{fig:seqlogo} \end{figure} \section{Data filtering and Clean-up} It should be considered whether any data should be removed in order to have a sound basis for developing a metric. When filtering VDJdb with a score of 1 or above, data of poor quality have already been removed. However, CDR3s of length above 20 were inspected. It was concluded that these TCRs bind the most abundant epitopes, which in this context means epitopes where the binding is more researched. Hence, the longer CDR3s are not an expression of abnormalities but rather an expression of lack of sequences. Without filtering on VDJdb scores, CDR3s up to the length of 38 appears. Hence, there will be no further removal of data. The distance metrics are applied to all 4346 TCRs.  Once the distance matrices have been calculated, a matrix of N*N distances is created. Here only a small subsection of these distances is kept. This is due to class imbalance. As illustrated in figure \ref{fig:length}, only a fraction of the pairwise TCR comparisons bind the same epitope according to the binary matrix presented for evaluation in section 5.4.3. This imbalance cause renders the classification unusable, and the negative class is sub-sampled down to fit the positive class. Hence, no TCRs are removed, as they as a minimum match themself, but some pairwise distances are not included.  \begin{figure}[h] \includegraphics[width=\textwidth]{graphics/Results_1/binar_distrib} \caption[Match distribution of distance metric]{Data imbalance based on binding specificity and how these are balanced based on data filtering after calculation of distance matrix. Barplots made in R and illustrations in google slides.} \includegraphics[width=\textwidth]{graphics/Results_1/circular_Epitope_distribution_ward} \caption[Dendrogram based on epitope similarity]{The similarity between the epitopes was calculated using the Blosum62 substitution matrix generating pairwise alignments between all epitopes. The method of connection chosen is ward. Dendrogram is made in R using the circlize library \section{Separation of data to train and test set.} The data was separated into a training- and a test-set, in accordance with the plan for the nested hold out method. This split was based on the similarity of the epitope to which the TCR binds. Division of the data is done, as not to train TCRs to recognize specific elements and then to test the elements on the precisely same epitopes, or highly similar epitopes. Testing on highly similar epitopes would defeat the purpose of splitting the data. Therefore each epitope is present in either the train- or the test-set. Basing the split solely on epitope identity with a pre-defined substitution matrix is a relatively easy task. Hence, all the epitopes underwent pairwise alignment with Blosum62, and a distance metric was extracted from this data. Plotting the distance metric resulted in the dendrogram figure \ref{fig:dendro}. Excluding any information regarding the TCRs in the split means that promiscuous TCRs are not taken into account, and two identical CDR3s might be placed in either group, as seen in figure \ref{fig:venn} this is the case for 3 CDR3s. There is a risk that this will cause uncertainty in the model, as the TCRs will be trained to recognize one thing, but the same CDR3 is tested towards another that is possibly quite different, as they are not deemed similar by Blosum62. Nevertheless, the point of introducing more parameters than Blosum62 in differentiating TCRs could, if the hypothesis hold true, overcome this issue. \caption[Data Split]{Data splitting diagram, illustrating the data present in the test and train set, named by their epitopes on a log-scale based on the TCR frequency, as well as a Venn diagram illustrating the number of CDR3s present in both. Graphs made in R using tidyverse and circulize libraries. Venn diagram put into the circluar barplot in google slides.}")
results2  = ("\chapter{Development of Distance Measure on the Training-data} The following chapter is the second of three results chapters, in which the outcome of the distance matrix calculation methods are presented. For each loop, the methods used to measure distance are evaluated based on performance in each of the three folds. The first section of this chapter describes how the distance libraries for CDR1 and CDR2 look, comparing them to each other. Secondly, a random forest for feature selection is presented and an ROC curve for each fold. The feature selection and area under the ROC curve determines the elements that, in combination, will be in the model for each fold. Coefficients for the combination of elements are applied using firstly logistic regression and secondly AdaBoost. Finally, the models are validated, and the best performing model is presented with Engelkings five principles of distance metrics. \caption[Example of CDR1 distance library]{Snippet of the CDR1 distance library. Each gene name and sequence is found on the IMGT database and structurally predicted using LYRA. The scores are generated as 1-TM-score, where the TM scores are calculated on structural alignment of anchored CDR1 structures \cite{Zhang2005TM-align:TM-score}} V-gene recognition is achieved by importing a library of structural distance information in a dictionary format, informing a distance between each pair of V-genes. The library of distances is a comma-separated file, where the column names and indexes are the gene names, enabling a gene search for each set of \(\beta\)-chains and their internal CDR1 or CDR2 distance, such as illustrated in table \ref{table:3} The libraries are inspected to gain an understanding of the measures. This inspection was done by generating dendrograms (using the Ward method) and generating heatmaps for these. In figure \ref{fig:CDR1_RMSDvTM} the heatmap for the TM distance and RMSD distance is depicted. Here it is evident that RMSD differentiates more conservatively between V-genes than the TM distance does. RMSD score seems to divide the V-genes into two groups, where each group is relatively similar but very different from each other. This grouping is based on the length of the sequences, as RMSD put much store by length difference. The TM score distances are in general more similar all around. Moreover, it is also evident that the TM scores are closely related to the canonical structures to which they were predicted by LYRA \cite{Klausen2015LYRAModeling}. Four canonical structures are available for CDR1: Canonical structures 1 and 2 are the most represented and the structures that can be seen as the larger and more related group. Structure 3 and 4 are much less represented but are distinctly different. When examining the dendrograms with relation lines in figure \ref{fig:CDR1_RMSDvTM}, it is visible that the RMSD dendrogram does not follow this relationship. This suggests that TM score might be a better measurement for structure distances unless the TCR:MHC contact is very dependent on the length of the CDR1 sequence. To determine sequence-based sidechain distances between CDR1 loops, Blosum62 and Kyte & Doolitles hydrophobicity scales were used, as illustrated in \ref{fig:CDR1_blos_hyd}. The hydrophobicity library distance heatmap shows two groups with close distance, which could suggest that some CDR1s are hydrophobic when others are hydrophilic. Suggesting that the distance between two hydrophilic CDR1s is less than that between a hydrophilic and hydrophobic CDR1. The CDR2 loop was evaluated using the same distance metrics as CDR1. Again the relationship between the TM distance and RMSD distance is available in figure \ref{fig:CDR2_TMvRMSD}. Again, it is evident that the TM score follows the seven canonical structures of CDR2, while the RMSD scores divide the genes en fewer categories. Determining sequence-based sidechain distances between CDR2 loops are again, Blosum62 and Kyte & Doolitles hydrophobicity scales were used, as illustrated in \ref{fig:CDR2_blosvhyd}. The hydrophobicity library distance heatmap show more or less one big group, deeming all CDR2 sequences to have similar hydrophobicity. In the opposite end of the spectrum is the Blosum62, which seems to find very little in common of the CDR2 sequences. Hence, it is expected that Blosum62 will be a harsher discriminator than the hydrophobicity scale for CDR2.  Here it is apparent that in fold 1, CDR1 is mainly explained by Blosum62. The structural information does not seem to relay much epitope-specific information for the TCR. However, it was never suspected that CDR1 or CDR2 alone would be able to inform the binding, why it is fascinating to see that the element that relays the largest part of the information regarding the epitope binding is the TM score for CDR2, with RMSD in close pursuit. This suggests that structural information is, as expected, an essential factor in epitope binding. For CDR3 in fold 1 the element that relays the most information is pam10 alignment and k-mer 3. This observation is consistent with the methods used in Immunomap and GLIPH \cite{Sidhom2018ImmunoMap:Access}, \cite{Glanville2017IdentifyingRepertoire}. Some elements, on the other hand, does not relay any information at all. Firstly the hydrophobicity of the CDR2. The difference here is very little, which probably is related to the fact that CDR2 loops are not buried. Furthermore, there is an entire section of CDR3 measures that do not seem to relay any information in either of the folds. These are k-mer 4 and 5, which might be too conservative measures. It is also all the physio-chemical properties of the CDR3 loop. This random forest analysis suggests that distance between CDR3s are better defined by substitution matrices that have some bio- and physio-chemical qualities inherent in them than the purely physical information. Fold 2 and fold 3 show identical information, here it is evident that for CDR1, the hydrophobicity and the blosum62 scores are important for binding. When plotting the distribution of v-genes in each fold, there is no suggestion of fold 2 and 3 having a higher v-gene diversity. The best purity measure for CDR2 in fold 2 and 3 seems to be TM score, following the same logic as fold 1. For CDR3, however, the element that is best at weeding out branches is Blosum45, this observation is consistent with findings by Thakkar et al., \cite{Thakkar2019BalancingSimilarity}. However, considering that fold 1 is different from the identical fold 2 and 3, the distances were examined. In figure \ref{fig:distance_diff}, the difference in distance of the binders (classified 1), and the non-binders (classified 0) is illustrated in percentages. Meaning that the sum of the distances for each method is computed to allow this comparison. Here it becomes apparent that measures such as CDR2 RMSD that have done reasonably well in the random forest selection have a relatively great difference in distance between the related TCRs and the non-related TCRs. Furthermore, the Atchley Factors and volume in solution are coming up short, having a larger distance in the binders than the non-binders. As seen in appendix 1, the distance measure itself is not reversed. Nevertheless, it seems that two TCRs with the same volume of CDR3s does not bind the same epitope. For all three folds, the difference in CDR1 and CDR2 is larger than the differences in CDR3. This might be due to the fact, that there is a finite amount of CDR1 and CDR2 options, why the diversity is decreased in comparison with CDR3. ")
results3  = ("\chapter{Performance of Distance Measure} In this last results chapter, the model is tested. The model is tested on its performance; 1) finding binders and non-binders and 2) on the ability to allocate TCRs to the different epitopes in clusters as well as 3) the computational time. Therefore, the structure of the code is presented, along the computational time. Next, the performance of the model, hereafter titled BetaDist, is presented and compared to state of the art methods.  \section{Overall structure and computational time} The distance metric can be downloaded from GitHub [] as a zip file and run by running the TCRdistancestart.py script in terminal (only tested on the Debian like system ubuntu): ./BetaDistanceStart.py > run\_distance.sh The user is prompted to enter the file path to the directory where they have placed the folder and the name of the tsv file to be examined. There is no GUI for the program, as the method is supposed to be integrated into diversity calculations. Writing the two parameters into the prompt will write out the steps needed to run the algorithm for that particular file in a bash script. To overcome large file sizes and handling making an n(TCR)*n(TCR) matrix, the tsv file is partitioned into sections of 50 TCRs, where each TCR is calculated against every TCR in the .tsv and saved in one file, termed chunks. Chunk 0 is then TCR 1 until TCR 50, and chunk 1 is TCR 51 to TCR 100 and so on. To calculate the betadist distances, four scripts are used. The TCRdist script is the wraparound script that allows the chunks to be calculated and printed. This script employs the distance calculations from two scripts, the CDR1, and CDR2 library importer and the CDR3 distance calculator. Hence, in order for the algorithm to run a directory with the libraries must be present in the file path. The distance measure algorithm takes a tsv file as input containing CDR3 sequences in the first column, V genes in the second and Epitopes in the third column. The distance can run without this third column, which is only applicable if evaluations of the distance metric are desired. The V-gene format needs to follow IMGT nomenclature with the deviation that the Asterix is exchanged for an underscore, TRBV09*01 become TRBV09\_01. After reading the input of the chunk, the wraparound parallelize the distance calculations to speed up the process. The overall flow of the core program to calculate the distance is illustrated in figure \ref{fig:Algo}. To start the program, write ./run\_distance.sh and make sure that the dependencies are satisfied: biopython, pandas, and NumPy. It takes X seconds for the first pair of TCRs, and X seconds for the following pairs, as the diagonal of all the TCRs are being aligned with Pam10 in order to scale the alignment scores when calculating the first pair. Hence, a dataset with 1000 TCRs will be calculated in ... seconds. All the scripts are available in appendix 5. \includegraphics[width=\textwidth]{graphics/results_4/core_algorithm}\caption[Algorithm flow diagram]{Algorithm flow diagram. This flow diagram illustrate how the distance is calculated. The red dotted line illustrate the algorithm itself.}\section{Performance of Distance Measure on Test-set} In the following section, the distance measure is applied to the test set, and it will be evaluated on the binary classification performance, AUC, and the ability to cluster on epitopes. The area under the curve for the model is 0.7085. There are two conclusions that can be drawn based on this: 1) the model is not over-fitted to the training data, 2) the model has an easier time differentiating between true positives and false positives in a dataset with fewer or more closely related epitopes. The resulting dendrogram is visible in figure \ref{fig:dendro}. \caption[Dendrogram of the testset]{Dendrogram of the test set when the model is the distance metric and ward is the method. It is hard to read the specific epitopes, yet it is evident that TCRs binding the epitope are closely related, as seen in the bottom right section. This epitope is quite different from the others.} The performance of the model on multidimensional data is tested based on clustering abilities; this is illustrated in figure \ref{fig:modelclus}. Here four clustering approaches are shown in a grid. It is evident, that even though there are clear clusters in the data, these are not related to the epitopes. As betadist have a substantial value placed on CDR2, the obvious explanation here is that the clusters are V-genes. When coloring the clusters based on v-genes, it becomes evident that this assumption is not completely wrong, yet the v-genes explain only the groups outside the two main groups. However, this does mean that BetaDist is not able to cluster on epitopes when using agglomerative hierarchical clustering. An alternative to this approach is to do affinity propagation. However, the pattern is the same. Affinity propagation using sklearn.cluster suggest 7 clusters that coincide with the first hierarchical clustering in figure \ref{fig:modelclus} and only with a rand index of 0.13. This plot is available in appendix 4. \centering \end{figure} \section{Comparison of Performance} In this section, the performance of the distance metric generated in this thesis is compared to state of the art: Immunodist \cite{Sidhom2018ImmunoMap:Access} and CDRdist \cite{Thakkar2019BalancingSimilarity}. They are compared based on the AUC, which is presented in figure \ref{fig:roc_all}. Here it is apparent that both Immunodist and CDRdist have an AUC of around 0.65. These two methods are based on the two alignment methods that did best in the feature selection. However, Blosum45 (used by CDRdist) did not perform well on the ROC in training, while here it performs as well as Immunodist. This might be due to smith waterman could be a better alignment algorithm than Goroth for CDR3 sequences.Furthermore, the BetaDist curve breaks around 0.25; from here, the predictive power stagnates. It is suspected that this is due to RMSD, which does have that characteristic. As seen in figure \ref{fig:pairs}, the profile of Betadist is very different from the other two. Here the profiles of the positives and negatives are different and somewhat more separated. As there is not so much weight placed on CDR3 which defy the literature, it would have been suspected that combining Betadist with either of the two methods would be even better at separating the two groups. However, when looking at the correlations between BetaDist and the two other CDR3 based distances, there does not seem to be any information gain. The main take away of these plots is the power of structure. Even though BetaDist has most of the weight placed on CDR1 and CDR2 and their structural predictions and it is well known that CDR3 has the largest contact with the epitope and should have the most substantial predictive power, BetaDist perform better on this data than both of these published methods.  Immunodist and CDRdist are not able to cluster on epitopes either, illustrations of this is found in appendix 4. ")
dis = ("As novel therapeutic solutions are needed in an ever-changing environment employing t-cells to fight these diseases is a paradigm shift from classical drug development. We are as a scientific community still in the relatively early phases of developing drugs that specifically target to aid t-cells. Hence, research into binding specificity and differences in these t-cells is needed to lay the foundations for these potential solutions. This discussion will shortly summarize the findings in this thesis, interpret and describe the significance of them as well as delve into the implications for developing these drugs. Lastly, limitations and future work will be discussed. The results indicate that combining multiple well-known protein comparison tools into one tool is better at differentiating t-cell receptors than using one tool on its own. Furthermore, the analysis confirms that structural predictions of CDR1 and CDR2 are appropriate tools to determine the distance between TCRs. Surprisingly, it was not apparent in the feature selection, that CDR3 mediate the main binding with the epitope, as CDR1 and CDR2 comparisons were given almost equal weights. That CDR3 is not the most important loop does not correlate with the general understanding of the TCR:p:MHC interaction. Furthermore, this might suggest one of three things: 1) that CDR1 and CDR2 have more control than previously anticipated, 2) that insufficient methods for CDR3 were chosen in this thesis, or 3) that structure is all-important. Nevertheless, it was possible to create a relatively robust distance metric that is able to identify if two t-cell receptors will bind the same epitope. Unfortunately, this separation is not perfect. However, the test-data suggest that this metric is better than readily available methods of distance measurements published within the past couple of years, respectively Immunodist \cite{Sidhom2018ImmunoMap:Access} and CDRdist \cite{Thakkar2019BalancingSimilarity}, why there is a potential for future work on this metric. The utilization of this metric is in diversity measures. As diversity is defined by abundance and similarity. Hence, having a biological significant distance measure will imply a different diversity, which in turn will map genetic differences between individuals and can, together with information about their response pattern, allow practitioners to map out which genetic fingerprints correspond to different therapeutic regimens. This is applicable in cancer, where one of the main questions in modern cancer treatment is why do some patients respond so well to immunotherapies, while others do not? In autoimmune diseases, this is a step on the way to assessing, how personal does personal medicine need to be? Are there any groups with a specific pattern, and how does this pattern or fingerprint differ from a healthy individual? Finally, in infectious diseases, allowing us to find differences and understand why some do not become ill with specific infectious diseases could be an approach to find novel therapeutics. In conclusion, a distance metric does open up more questions than it answers, but can, when integrated with other measures, be a powerful tool. Even though this metric has shown itself just as good or potentially better than the baseline distance metric, there are some clear limitations to the method. First of all, a TCR is not just one subunit, and with the larger deposit of paired data, the alpha chain should be included in the metric. Furthermore, the metric is not able to differentiate epitopes or epitope groups. However, epitope similarity concerning what TCRs bind might not be mediated based on what protein theory perceives as similar based on Blosum62. Hence, there are still many questions to be answered in regard to t-cells, and the gap from a potential to a solution is still not entirely bridged. However, with more time, the following parameters would be interesting to delve into in order to improve the metric. Firstly, more methods for testing could have been employed, as the choice of methods limits the final model, and integrating the LYRA framework for loops modeling for CDR3 could be an interesting study.  Another improvement to this study is to deal with the imbalance of the data in a more sophisticated fashion, such as using an up-sampling algorithm, thus not losing any data. There is a chance that logistic regression could have been successful in this case, and the somewhat pushing of the AdaBoost algorithm to force coefficient would not have been needed. In relation to coefficients, testing physio-chemical distances as coefficients would also be an interesting approach. This was tested briefly with volume without any information gain, yet a more structured approach to these parameters would be interesting to test. Furthermore, when converting physio-chemical properties into distances, it was done in a considerably ad-hoc way to ensure a mathematical distance rather than deeply analyze the methods. In conclusion, there are many untraveled avenues to develop this metric, and it is suspected that many and hopefully better metrics will follow this one, as both understanding of t-cell receptors and the ability to model CDR3 sequences expand. On that note, to develop a good distance metric for t-cells, the two following parameters should be established:\begin{itemize} \item Epitope binding - The characteristics of promiscuous TCRs. \\In order to better the evaluation of metrics, a clear understanding of binding motifs for CDR3s would be beneficial.  \item CDR3 structure \\  Structures of CDR1 and CDR2 proved themself advantageous, why a way to measure the similarity of structures for CDR3 without solving the structures should be included in the metric. \end{itemize} Finally, there are also options in optimizing the code. For starters, only calculating the upper triangular of the n*n matrix would increase efficiency and decrease time and memory storage, which naturally is all desirable goals. Other ways to make the code more efficient, is by collecting the libraries so the program should not fetch distances from four dictionaries, two for CDR1 and two for CDR2, but that one library was constructed with one V-gene score based on the distances and coefficients of CDR1 and CDR2. Fetching the scores in the dictionaries is a fast process already, why it would not have the same effect as only calculating the upper triangular. Secondly, there might be more efficient ways of calculating Pam10 than using biopython. Developers of Immunodist \cite{Sidhom2018ImmunoMap:Access} were able to make an incredibly fast tool in MatLab where Needleman-Wunsch alignment is native rather than a package. Potentially there are options in using another framework than python. Furthermore, there might be better ways to scale the results of the alignment. At present, all self alignments are calculated and saved in an array to be used for scaling. This considerably decreased the calculation time; however, other measures might be used to achieve this result, again drawing inspiration from Immunodist.")
conc  = ("The t-cell receptor is a heterodimeric surface receptor consisting of an \(\alpha\) and a \(\beta\)-subunit, while the main contact is mediated by the very tip of these termed complementary determining regions. The t-cell receptor has  incomprehensible gene rearrangement options accounting for an incredibly diverse receptor pool in each of us. Understanding this genetic pool is needed in order to tailor therapeutic regimen and develop new treatment options based on elements most likely to elicit an immunological response. Hence, diversity should be quantified. Diversity is a function of abundance and similarity, yet defining similarity of T-cell receptors concerning their peptide:major histocompatibility complex binding has not proven a trivial task. This thesis investigates how different protein comparison techniques can be utilized to develop such a similarity measure in the format of a distance between the complementary determining regions of the  \(\beta\)-subunit. To answer the question of finding the best elements of measuring distance between t-cell receptors, protein comparison techniques in three categories were selected: alignment techniques, physio-chemical techniques, and structural comparison techniques. For complementary determining regions one and two four tools were used, while ten tools were used to analyze complementary determining region three. Each technique was converted to a distance measure and applied to a set of \(\beta\)-subunits in 3-fold nested cross-validation, resulting in matrices of pairwise distances. The techniques were evaluated as classifiers in a binary classification problem. The best techniques were selected based on feature selection with random forest and area under the receiver operator characteristics curve. After the removal of the classifiers with the worst scores, the remaining classifiers were quantified in combination using the Adaboost algorithm iteratively assigning coefficients to the classifiers to optimize accuracy. The distance metric with the best performance in the folds was used on a test set and compared to state of the art methods.  The resulting metric, BetaDist, use structural comparisons for complementary determining region one and two in combination with the Pam10 alignment score with a gap-penalty of 30 for the complementary determining region three sequences. BetaDist performs better than other \(\beta\)-subunit distance metrics when evaluated on classification power. This thesis emphasizes the need to use structural predictions in determining differences in T-cell receptors if real understanding and classification of similarity should be assessed. An approach to address diseases without effective therapeutic regimens is to develop novel therapeutics based on genetic differences in our T-cell repertoires. In order to analyze the repertories, assessment of frequency, and similarity is needed. This thesis aimed to produce a distance metric to calculate the dissimilarity between TCR \(\beta\)-subunits, with the hypothesis that a short distance would indicate binding of the same epitope, and a long-distance would indicate binding of different epitopes. The distance metric was build by collecting different protein comparison techniques and applying these to the CDR sequences. Afterward assessing which techniques were able to achieve the largest purity gain based on feature selection algorithms. The concluding distance metric is:\begin{equation}\begin{split}BetaDist(TCR\beta_{i}, TCR\beta_{j}) & = (0.15 * Blosum62(CDR1_{i},_{j}) + 0.17 * TM(CDR1_{i},_{j}) \\ & + (0.28 * TM(CDR2_{i},_{j}) + 0.21 * RMSD(CDR2_{i},_{j}) \\& + (0.19 * Pam10(CDR3_{i},_{j}) \\ \end{split} \end{equation} Hence, all three complementary determining regions are included with the largest emphasis on CDR1 and CDR2, which is in direct opposition to current knowledge of T-cell binding. Betadist showed itself better than direct \(\beta\)-subunit competitors in differentiating between binders and non-binders based on distance, proving the hypothesis true. Although Betadist is not able to differentiate perfectly and this thesis can, therefore, conclude, that structural distances have the greatest potential and developing a distance based on structural comparisons of CDR3. Future work should integrate this structural element. ")

a = re.findall(r"\b(?:[A-Z][a-z]*){2,}", background)
b = re.findall(r"\b(?:[A-Z][a-z]*){2,}", aim_hypo)
c = re.findall(r"\b(?:[A-Z][a-z]*){2,}", Theory1)
d = re.findall(r"\b(?:[A-Z][a-z]*){2,}", Theory2)
e = re.findall(r"\b(?:[A-Z][a-z]*){2,}", Theory3)
f = re.findall(r"\b(?:[A-Z][a-z]*){2,}", methods)
g = re.findall(r"\b(?:[A-Z][a-z]*){2,}", results1)
h = re.findall(r"\b(?:[A-Z][a-z]*){2,}", results2)
i = re.findall(r"\b(?:[A-Z][a-z]*){2,}", results3)
j = re.findall(r"\b(?:[A-Z][a-z]*){2,}", dis)
k = re.findall(r"\b(?:[A-Z][a-z]*){2,}", conc)


all_ = a+b+c+d+f+g+h+i+j+k

all_.sort()

print(set(all_))